@article{yue2023fedjudge,
  title   = {FedJudge: Federated Legal Large Language Model},
  author  = {Yue, Linan and Liu, Qi and Du, Yichao and Gao, Weibo and Liu, Ye and Yao, Fangzhou},
  journal = {arXiv preprint arXiv:2309.08173},
  url     = {https://doi.org/10.48550/arXiv.2309.08173},
  github  = {https://github.com/yuelinan/FedJudge},
  tags    = {application, domain specific},
  year    = {2023}
}

@article{tang2023does,
  title         = {Does Synthetic Data Generation of LLMs Help Clinical Text Mining?},
  author        = {Ruixiang Tang and Xiaotian Han and Xiaoqian Jiang and Xia Hu},
  year          = {2023},
  eprint        = {2303.04360},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2303.04360},
  journal       = {arXiv preprint arXiv:2303.04360}
}

@article{nguyen2022federated,
  title     = {Federated learning for smart healthcare: A survey},
  author    = {Nguyen, Dinh C and Pham, Quoc-Viet and Pathirana, Pubudu N and Ding, Ming and Seneviratne, Aruna and Lin, Zihuai and Dobre, Octavia and Hwang, Won-Joo},
  journal   = {ACM Computing Surveys (CSUR)},
  volume    = {55},
  number    = {3},
  pages     = {1--37},
  year      = {2022},
  publisher = {ACM New York, NY}
}

@inproceedings{zhang2023fedpetuning,
  title     = {{F}ed{PET}uning: When Federated Learning Meets the Parameter-Efficient Tuning Methods of Pre-trained Language Models},
  author    = {Zhang, Zhuo  and
               Yang, Yuanhang  and
               Dai, Yong  and
               Wang, Qifan  and
               Yu, Yue  and
               Qu, Lizhen  and
               Xu, Zenglin},
  editor    = {Rogers, Anna  and
               Boyd-Graber, Jordan  and
               Okazaki, Naoaki},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2023},
  month     = jul,
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.findings-acl.632},
  doi       = {10.18653/v1/2023.findings-acl.632},
  pages     = {9963--9977}
}

@article{ding2022delta,
  title   = {Delta tuning: A comprehensive study of parameter efficient methods for pre-trained language models},
  author  = {Ding, Ning and Qin, Yujia and Yang, Guang and Wei, Fuchao and Yang, Zonghan and Su, Yusheng and Hu, Shengding and Chen, Yulin and Chan, Chi-Min and Chen, Weize and others},
  journal = {arXiv preprint arXiv:2203.06904},
  year    = {2022}
}


@article{guo2023promptfl,
  author  = {Guo, Tao and Guo, Song and Wang, Junxiao and Tang, Xueyang and Xu, Wenchao},
  journal = {IEEE Transactions on Mobile Computing},
  title   = {PromptFL: Let Federated Participants Cooperatively Learn Prompts Instead of Models - Federated Learning in Age of Foundation Model},
  year    = {2023},
  volume  = {},
  number  = {},
  month   = {aug},
  pages   = {1-15},
  venue   = {TMC},
  tags    = {efficiency, additive tuning, prompt tuning, textual-visual prompt tuning},
  doi     = {10.1109/TMC.2023.3302410},
  url     = {https://ieeexplore.ieee.org/abstract/document/10210127}
}


@inproceedings{
luo2024mixture,
title={Mixture of Experts Made Personalized: Federated Prompt Learning for Vision-Language Models},
author={Jun Luo and Chen Chen and Shandong Wu},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
venue = {ICLR},
month = {apr},
tags    = {efficiency, additive tuning, prompt tuning, textual-visual prompt tuning},
url={https://openreview.net/forum?id=xiDJaTim3P}
}


@inproceedings{NEURIPS2022_7aa320d2,
  author    = {Tan, Yue and Long, Guodong and Ma, Jie and LIU, LU and Zhou, Tianyi and Jiang, Jing},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
  pages     = {19332--19344},
  publisher = {Curran Associates, Inc.},
  title     = {Federated Learning from Pre-Trained Models: A Contrastive Learning Approach},
  url       = {https://proceedings.neurips.cc/paper\_files/paper/2022/file/7aa320d2b4b8f6400b18f6f77b6c1535-Paper-Conference.pdf},
  volume    = {35},
  year      = {2022}
}


@inproceedings{zhao2023fedprompt,
  title        = {FedPrompt: Communication-Efficient and Privacy-Preserving Prompt Tuning in Federated Learning},
  author       = {Zhao, Haodong and Du, Wei and Li, Fangqi and Li, Peixuan and Liu, Gongshen},
  booktitle    = {ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  url          = {https://ieeexplore.ieee.org/document/10095356},
  pages        = {1--5},
  month        = {may},
  year         = {2023},
  venue        = {ICASSP},
  tags         = {efficiency, additive tuning, prompt tuning, textual prompt tuning},
  organization = {IEEE}
}

@inproceedings{mcmahan2017communication,
  title        = {Communication-efficient learning of deep networks from decentralized data},
  author       = {McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle    = {Artificial intelligence and statistics},
  pages        = {1273--1282},
  year         = {2017},
  url          = {https://proceedings.mlr.press/v54/mcmahan17a.html},
  organization = {PMLR}
}


@article{bommasani2021opportunities,
  title   = {On the opportunities and risks of foundation models},
  author  = {Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal = {arXiv preprint arXiv:2108.07258},
  url     = {https://arxiv.org/abs/2108.07258},
  year    = {2021}
}

@article{zhao2023survey,
  title   = {A survey of large language models},
  author  = {Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal = {arXiv preprint arXiv:2303.18223},
  url     = {https://arxiv.org/abs/2303.18223},
  year    = {2023}
}

@inproceedings{351095.3372829,
  author    = {Jo, Eun Seo and Gebru, Timnit},
  title     = {Lessons from Archives: Strategies for Collecting Sociocultural Data in Machine Learning},
  year      = {2020},
  isbn      = {9781450369367},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3351095.3372829},
  doi       = {10.1145/3351095.3372829},
  booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  pages     = {306--316},
  numpages  = {11},
  keywords  = {data collection, machine learning, ML fairness, datasets, sociocultural data, archives},
  location  = {Barcelona, Spain},
  series    = {FAcctT '20}
}

@article{openai2023gpt4,
  title         = {GPT-4 Technical Report},
  author        = {{OpenAI}},
  year          = {2024},
  eprint        = {2303.08774},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2303.08774},
  journal       = {arXiv preprint arXiv:2303.08774}
}

@inproceedings{brown2020language,
  author    = {Brown, Tom and others},
  editor    = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {1877--1901},
  publisher = {Curran Associates, Inc.},
  title     = {Language Models are Few-Shot Learners},
  url       = {https://proceedings.neurips.cc/paper\_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
  volume    = {33},
  year      = {2020}
}
%author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},


@article{touvron2023llama,
  title   = {Llama: Open and efficient foundation language models},
  author  = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal = {arXiv preprint arXiv:2302.13971},
  url     = {https://arxiv.org/abs/2302.13971},
  year    = {2023}
}

@inproceedings{ramesh2021zero,
  title        = {Zero-shot text-to-image generation},
  author       = {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle    = {International Conference on Machine Learning},
  pages        = {8821--8831},
  year         = {2021},
  url          = {https://proceedings.mlr.press/v139/ramesh21a.html},
  organization = {PMLR}
}

@inproceedings{radford2021learning,
  title        = {Learning transferable visual models from natural language supervision},
  author       = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle    = {International conference on machine learning},
  pages        = {8748--8763},
  year         = {2021},
  url          = {https://proceedings.mlr.press/v139/radford21a.html},
  organization = {PMLR}
}

@misc{openai2023chatgpt,
  title  = {ChatGPT},
  author = {OpenAI},
  year   = {2022},
  url    = {https://openai.com/blog/chatgpt/}
}

@misc{grok,
  title  = {Grok},
  author = {X},
  year   = {2023},
  url    = {https://grok.x.ai}
}

@misc{claude3,
  title  = {Claude 3},
  author = {Anthropic},
  year   = {2024},
  url    = {https://www.anthropic.com/claude}
}

@article{zhang2023federated,
  title   = {Federated generative learning with foundation models},
  author  = {Zhang, Jie and Qi, Xiaohua and Zhao, Bo},
  journal = {arXiv preprint arXiv:2306.16064},
  url     = {https://doi.org/10.48550/arXiv.2306.16064},
  year    = {2023}
}

@inproceedings{che2023federated,
  title     = {Federated Learning of Large Language Models with Parameter-Efficient Prompt Tuning and Adaptive Optimization},
  author    = {Che, Tianshi  and
               Liu, Ji  and
               Zhou, Yang  and
               Ren, Jiaxiang  and
               Zhou, Jiwen  and
               Sheng, Victor  and
               Dai, Huaiyu  and
               Dou, Dejing},
  editor    = {Bouamor, Houda  and
               Pino, Juan  and
               Bali, Kalika},
  booktitle = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  month     = dec,
  year      = {2023},
  address   = {Singapore},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.emnlp-main.488},
  doi       = {10.18653/v1/2023.emnlp-main.488},
  github    = {https://github.com/llm-eff/FedPepTAO},
  venue     = {EMNLP},
  tags      = {efficiency, additive tuning, prompt tuning, textual prompt tuning},
  pages     = {7871--7888}
}

@inproceedings{guo2023pfedprompt,
  title     = {pFedPrompt: Learning Personalized Prompt for Vision-Language Models in Federated Learning},
  author    = {Guo, Tao and Guo, Song and Wang, Junxiao},
  booktitle = {Proceedings of the ACM Web Conference 2023},
  pages     = {1364--1374},
  url       = {https://doi.org/10.1145/3543507.3583518},
  doi       = {10.1145/3543507.3583518},
  month     = {apr},
  venue     = {WWW},
  tags      = {effiency, additive tuning,  prompt tuning, vision-language models, textual-visual prompt tuning},
  year      = {2023}
}

@inproceedings{hu2022lora,
  title     = {Lo{RA}: Low-Rank Adaptation of Large Language Models},
  author    = {Edward J Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
  booktitle = {International Conference on Learning Representations},
  year      = {2022},
  url       = {https://openreview.net/forum?id=nZeVKeeFYf9}
}

@inproceedings{zhang2023towards,
  author    = {Zhang, Jianyi and Vahidian, Saeed and Kuo, Martin and Li, Chunyuan and Zhang, Ruiyi and Yu, Tong and Wang, Guoyin and Chen, Yiran},
  booktitle = {ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Towards Building The Federatedgpt: Federated Instruction Tuning},
  year      = {2024},
  volume    = {},
  number    = {},
  pages     = {6915-6919},
  venue     = {ICASSP},
  month     = {mar},
  github    = {https://github.com/JayZhang42/FederatedGPT-Shepherd},
  tags      = {efficiency, LoRA, reparameterization-based},
  url       = {https://ieeexplore.ieee.org/document/10447454},
  keywords  = {Training;Performance evaluation;Costs;Sensitivity;Instruction sets;Oral communication;Signal processing},
  doi       = {10.1109/ICASSP48485.2024.10447454}
}


@inproceedings{li2021prefix,
  title     = {Prefix-Tuning: Optimizing Continuous Prompts for Generation},
  author    = {Li, Xiang Lisa  and
               Liang, Percy},
  editor    = {Zong, Chengqing  and
               Xia, Fei  and
               Li, Wenjie  and
               Navigli, Roberto},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  month     = aug,
  year      = {2021},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.acl-long.353},
  doi       = {10.18653/v1/2021.acl-long.353},
  pages     = {4582--4597}
}

@inproceedings{sun2023fedperfix,
  title     = {FedPerfix: Towards Partial Model Personalization of Vision Transformers in Federated Learning},
  author    = {Sun, Guangyu and Mendieta, Matias and Luo, Jun and Wu, Shandong and Chen, Chen},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages     = {4988--4998},
  url       = {https://openaccess.thecvf.com/content/ICCV2023/html/Sun\_FedPerfix\_Towards_Partial_Model_Personalization_of_Vision_Transformers_in_Federated_ICCV_2023_paper.html},
  year      = {2023}
}

@inproceedings{gururangandont,
  title     = {Don{'}t Stop Pretraining: Adapt Language Models to Domains and Tasks},
  author    = {Gururangan, Suchin  and
               Marasovi{\'c}, Ana  and
               Swayamdipta, Swabha  and
               Lo, Kyle  and
               Beltagy, Iz  and
               Downey, Doug  and
               Smith, Noah A.},
  editor    = {Jurafsky, Dan  and
               Chai, Joyce  and
               Schluter, Natalie  and
               Tetreault, Joel},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.acl-main.740},
  doi       = {10.18653/v1/2020.acl-main.740},
  pages     = {8342--8360}
}

@inproceedings{jiang2023fdapt,
  title     = {{FDAPT}: Federated Domain-adaptive Pre-training for Language Models},
  author    = {Lekang Jiang and Filip Svoboda and Nicholas Donald Lane},
  booktitle = {International Workshop on Federated Learning in the Age of Foundation Models in Conjunction with NeurIPS 2023},
  year      = {2023},
  url       = {https://openreview.net/forum?id=ESCL5T3EgV}
}

@inproceedings{ijcai2023p483,
  title     = {FedBFPT: An Efficient Federated Learning Framework for Bert Further Pre-training},
  author    = {Wang, Xin'ao and Li, Huan and Chen, Ke and Shou, Lidan},
  booktitle = {Proceedings of the Thirty-Second International Joint Conference on
               Artificial Intelligence, {IJCAI-23}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Edith Elkind},
  pages     = {4344--4352},
  year      = {2023},
  month     = {8},
  note      = {Main Track},
  doi       = {10.24963/ijcai.2023/483},
  url       = {https://doi.org/10.24963/ijcai.2023/483}
}


@inproceedings{pmlr-v232-malaviya23a,
  title     = {Reducing Communication Overhead in Federated Learning for Pre-trained Language Models Using Parameter-Efficient Finetuning},
  author    = {Malaviya, Shubham and Shukla, Manish and Lodha, Sachin},
  booktitle = {Proceedings of The 2nd Conference on Lifelong Learning Agents},
  pages     = {456--469},
  year      = {2023},
  editor    = {Chandar, Sarath and Pascanu, Razvan and Sedghi, Hanie and Precup, Doina},
  volume    = {232},
  series    = {Proceedings of Machine Learning Research},
  month     = {22--25 Aug},
  publisher = {PMLR},
  pdf       = {https://proceedings.mlr.press/v232/malaviya23a/malaviya23a.pdf},
  url       = {https://proceedings.mlr.press/v232/malaviya23a.html}
}

@article{lu2023fedclip,
  author    = {Wang Lu and
               Xixu Hu and
               Jindong Wang and
               Xing Xie},
  title     = {FedCLIP: Fast Generalization and Personalization for {CLIP} in Federated Learning},
  journal   = {{IEEE} Data Eng. Bull.},
  volume    = {46},
  venue     = {IEEE DEB},
  number    = {1},
  month     = {mar},
  pages     = {52--66},
  year      = {2023},
  tags      = {efficiency, additive tuning, adapter tuning, adaptability, client-centric adaptation},
  url       = {http://sites.computer.org/debull/A23mar/p52.pdf},
  timestamp = {Tue, 13 Jun 2023 16:59:20 +0200},
  biburl    = {https://dblp.org/rec/journals/debu/LuH0023.bib},
  github    = {https://github.com/microsoft/PersonalizedFL},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@misc{wu2024clientpreferencellmfinetuning,
  title         = {On the Client Preference of LLM Fine-tuning in Federated Learning},
  author        = {Feijie Wu and Xiaoze Liu and Haoyu Wang and Xingchen Wang and Jing Gao},
  year          = {2024},
  eprint        = {2407.03038},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  tags          = {adaptability, client-centric adaptation},
  url           = {https://arxiv.org/abs/2407.03038}
}

@inproceedings{
anonymous2025towards,
title={Towards Federated {RLHF} with Aggregated Client Preference for {LLM}s},
  author        = {Feijie Wu and Xiaoze Liu and Haoyu Wang and Xingchen Wang and Jing Gao},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
  tags          = {adaptability, client-centric adaptation},
venue = {ICLR},
month = {apr},
url={https://openreview.net/forum?id=mqNKiEB6pd}
}


@inproceedings{
fan2024fedrlhfconvergenceguaranteedfederatedframework,
title={FedRLHF: A Convergence-Guaranteed Federated Framework for Privacy-Preserving and Personalized RLHF},
author = {Flint Xiaofeng Fan and Cheston Tan and Yew-Soon Ong and Roger Wattenhofer and Wei-Tsang Ooi},
booktitle = {The Thirteenth International Conference on Learning Representations},
year={2025},
tags          = {adaptability, client-centric adaptation},
venue = {AAMAS},
month = {may},
url={https://arxiv.org/abs/2412.15538}
}


@article{chua2023fedpeat,
  title   = {FedPEAT: Convergence of Federated Learning, Parameter-Efficient Fine Tuning, and Emulator Assisted Tuning for Artificial Intelligence Foundation Models with Mobile Edge Computing},
  author  = {Chua, Terence Jie and Yu, Wenhan and Zhao, Jun and Lam, Kwok-Yan},
  journal = {arXiv preprint arXiv:2310.17491},
  url     = {https://arxiv.org/abs/2310.17491},
  year    = {2023}
}

@inproceedings{kimetal2023client,
  title     = {Client-Customized Adaptation for Parameter-Efficient Federated Learning},
  author    = {Kim, Yeachan  and
               Kim, Junho  and
               Mok, Wing-Lam  and
               Park, Jun-Hyung  and
               Lee, SangKeun},
  editor    = {Rogers, Anna  and
               Boyd-Graber, Jordan  and
               Okazaki, Naoaki},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2023},
  month     = jul,
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.findings-acl.75},
  doi       = {10.18653/v1/2023.findings-acl.75},
  pages     = {1159--1172}
}

@article{sun2022conquering,
  title   = {Conquering the Communication Constraints to Enable Large Pre-Trained Models in Federated Learning},
  author  = {Sun, Guangyu and Mendieta, Matias and Yang, Taojiannan and Chen, Chen},
  journal = {arXiv preprint arXiv:2210.01708},
  doi     = {https://doi.org/10.48550/arXiv.2210.01708},
  year    = {2022}
}


@article{yi2023fedlora,
  title         = {pFedLoRA: Model-Heterogeneous Personalized Federated Learning with LoRA Tuning},
  author        = {Liping Yi and Han Yu and Gang Wang and Xiaoguang Liu and Xiaoxiao Li},
  year          = {2024},
  eprint        = {2310.13283},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  tags          = {efficiency, reparameterization-based, LoRA, heterogeneous resource, personalization},
  url           = {https://arxiv.org/abs/2310.13283},
  journal       = {arXiv preprint arXiv:2310.13283}
}

@inproceedings{
anonymous2025federated,
title={Federated Residual Low-Rank Adaption of Large Language Models},
author={Anonymous},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
venue = {ICLR},
  tags          = {efficiency, reparameterization-based, LoRA},
month = {apri},
url={https://openreview.net/forum?id=e0rQRMUhs7}
}


@article{ding2023parameter,
  title     = {Parameter-efficient fine-tuning of large-scale pre-trained language models},
  author    = {Ding, Ning and Qin, Yujia and Yang, Guang and Wei, Fuchao and Yang, Zonghan and Su, Yusheng and Hu, Shengding and Chen, Yulin and Chan, Chi-Min and Chen, Weize and others},
  journal   = {Nature Machine Intelligence},
  volume    = {5},
  number    = {3},
  pages     = {220--235},
  year      = {2023},
  doi       = {https://doi.org/10.1038/s42256-023-00626-4},
  publisher = {Nature Publishing Group UK London}
}


@inproceedings{pmlr-v97-houlsby19a,
  title     = {Parameter-Efficient Transfer Learning for {NLP}},
  author    = {Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  pages     = {2790--2799},
  year      = {2019},
  editor    = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume    = {97},
  series    = {Proceedings of Machine Learning Research},
  month     = {09--15 Jun},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v97/houlsby19a/houlsby19a.pdf},
  url       = {https://proceedings.mlr.press/v97/houlsby19a.html}
}

@article{lialin2023scaling,
  title   = {Scaling down to scale up: A guide to parameter-efficient fine-tuning},
  author  = {Lialin, Vladislav and Deshpande, Vijeta and Rumshisky, Anna},
  journal = {arXiv preprint arXiv:2303.15647},
  doi     = {https://doi.org/10.48550/arXiv.2303.15647},
  year    = {2023}
}

@inproceedings{ha2017hypernetworks,
  title     = {HyperNetworks},
  author    = {David Ha and Andrew M. Dai and Quoc V. Le},
  booktitle = {International Conference on Learning Representations},
  year      = {2017},
  url       = {https://openreview.net/forum?id=rkpACe1lx}
}

@inproceedings{tamirisa2023fedselect,
  title     = {FedSelect: Customized Selection of Parameters for Fine-Tuning during Personalized Federated Learning},
  author    = {Rishub Tamirisa and John Won and Chengjun Lu and Ron Arel and Andy Zhou},
  booktitle = {Federated Learning and Analytics in Practice: Algorithms, Systems, Applications, and Opportunities},
  year      = {2024},
  venue     = {CVPR},
  month     = {jun},
  tags      = {efficiency, selective tuning, adaptability, client-centric adaptation},
  url       = {https://openreview.net/forum?id=TXtRWPZIZ0}
}


@misc{kuo2024federatedlorasparsecommunication,
  title         = {Federated LoRA with Sparse Communication},
  author        = {Kevin Kuo and Arian Raje and Kousik Rajesh and Virginia Smith},
  year          = {2024},
  eprint        = {2406.05233},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  github        = {https://github.com/imkevinkuo/flasc},
  tags          = {efficiency, selective tuning, reparameterization-based, LoRA, sparsification},
  url           = {https://arxiv.org/abs/2406.05233}
}


@misc{wang2024saveallenablingparameter,
  title         = {Save It All: Enabling Full Parameter Tuning for Federated Large Language Models via Cycle Block Gradient Descent},
  author        = {Lin Wang and Zhichao Wang and Xiaoying Tang},
  year          = {2024},
  eprint        = {2406.11187},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  tags          = {efficiency, sparsification},
  url           = {https://arxiv.org/abs/2406.11187},
  github        = {https://github.com/L3030/FedCyBGD}
}

@inproceedings{chen2023on,
  title     = {On the Importance and Applicability of Pre-Training for Federated Learning},
  author    = {Hong-You Chen and Cheng-Hao Tu and Ziwei Li and Han Wei Shen and Wei-Lun Chao},
  booktitle = {The Eleventh International Conference on Learning Representations },
  year      = {2023},
  url       = {https://openreview.net/forum?id=fWWFv--P0xP}
}


@article{guo2022domain,
  title   = {On the Domain Adaptation and Generalization of Pretrained Language Models: A Survey},
  author  = {Guo, Xu and Yu, Han},
  journal = {arXiv preprint arXiv:2211.03154},
  url     = {https://doi.org/10.48550/arXiv.2211.03154},
  year    = {2022}
}

@article{kairouz2021advances,
  url     = {http://dx.doi.org/10.1561/2200000083},
  year    = {2021},
  volume  = {14},
  journal = {Foundations and Trends in Machine Learning},
  title   = {Advances and Open Problems in Federated Learning},
  doi     = {10.1561/2200000083},
  issn    = {1935-8237},
  pages   = {1-210},
  author  = {Peter Kairouz and others}
}

@inproceedings{babakniya2023slora,
  title     = {{SL}o{RA}: Federated Parameter Efficient Fine-Tuning of Language Models},
  author    = {Sara Babakniya and Ahmed Elkordy and Yahya Ezzeldin and Qingfeng Liu and Kee-Bong Song and MOSTAFA EL-Khamy and Salman Avestimehr},
  booktitle = {International Workshop on Federated Learning in the Age of Foundation Models in Conjunction with NeurIPS 2023},
  year      = {2023},
  venue     = {FL\@FM-NeurIPS},
  month     = {dec},
  tags      = {efficiency, reparameterization-based, LoRA, sparsification},
  url       = {https://openreview.net/forum?id=06quMTmtRV}
}

@inproceedings{9835537,
  author    = {Li, Qinbin and Diao, Yiqun and Chen, Quan and He, Bingsheng},
  booktitle = {2022 IEEE 38th International Conference on Data Engineering (ICDE)},
  title     = {Federated Learning on Non-IID Data Silos: An Experimental Study},
  year      = {2022},
  volume    = {},
  number    = {},
  pages     = {965-978},
  doi       = {10.1109/ICDE53745.2022.00077}
}

@article{touvron2023llama2,
  title   = {Llama 2: Open foundation and fine-tuned chat models},
  author  = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal = {arXiv preprint arXiv:2307.09288},
  url     = {https://doi.org/10.48550/arXiv.2307.09288},
  year    = {2023}
}

@inproceedings{frankle2018the,
  title     = {The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks},
  author    = {Jonathan Frankle and Michael Carbin},
  booktitle = {International Conference on Learning Representations},
  year      = {2019},
  url       = {https://openreview.net/forum?id=rJl-b3RcF7}
}

@inproceedings{chen2023finegrained,
  title     = {Fine-Grained Theoretical Analysis of Federated Zeroth-Order Optimization},
  author    = {Jun Chen and Hong Chen and Bin Gu and Hao Deng},
  booktitle = {Thirty-seventh Conference on Neural Information Processing Systems},
  year      = {2023},
  url       = {https://openreview.net/forum?id=0ycX03sMAT}
}



@inproceedings{pmlr-v162-sun22e,
  title     = {Black-Box Tuning for Language-Model-as-a-Service},
  author    = {Sun, Tianxiang and Shao, Yunfan and Qian, Hong and Huang, Xuanjing and Qiu, Xipeng},
  booktitle = {Proceedings of the 39th International Conference on Machine Learning},
  pages     = {20841--20855},
  year      = {2022},
  editor    = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume    = {162},
  series    = {Proceedings of Machine Learning Research},
  month     = {17--23 Jul},
  publisher = {PMLR},
  pdf       = {https://proceedings.mlr.press/v162/sun22e/sun22e.pdf},
  url       = {https://proceedings.mlr.press/v162/sun22e.html}
}


@inproceedings{bu2022differentially,
  title     = {Differentially Private Bias-Term only Fine-tuning of Foundation Models},
  author    = {Zhiqi Bu and Yu-Xiang Wang and Sheng Zha and George Karypis},
  booktitle = {Workshop on Trustworthy and Socially Responsible Machine Learning, NeurIPS 2022},
  year      = {2022},
  url       = {https://openreview.net/forum?id=6Bo1vhoHolh}
}


@article{su2023fedra,
  title   = {FedRA: A Random Allocation Strategy for Federated Tuning to Unleash the Power of Heterogeneous Clients},
  author  = {Su, Shangchao and Li, Bin and Xue, Xiangyang},
  github  = {https://github.com/leondada/FedRA},
  tags    = {efficiency, reparameterization-based, LoRA, heterogeneous resource},
  journal = {arXiv preprint arXiv:2311.11227},
  url     = {https://doi.org/10.48550/arXiv.2311.11227},
  venue   = {ECCV},
  month   = {oct},
  year    = {2024}
}

@article{lu2023zoopfl,
  title   = {ZooPFL: Exploring Black-box Foundation Models for Personalized Federated Learning},
  author  = {Lu, Wang and Yu, Hao and Wang, Jindong and Teney, Damien and Wang, Haohan and Chen, Yiqiang and Yang, Qiang and Xie, Xing and Ji, Xiangyang},
  journal = {arXiv preprint arXiv:2310.05143},
  url     = {https://doi.org/10.48550/arXiv.2310.05143},
  tags    = {efficiency, trustworthiness, ip protection, black-box tuning, zeroth-order optimization},
  year    = {2023}
}





@article{abs-2310-03123,
  author     = {Zihao Lin and
                Yan Sun and
                Yifan Shi and
                Xueqian Wang and
                Lifu Huang and
                Li Shen and
                Dacheng Tao},
  title      = {Efficient Federated Prompt Tuning for Black-box Large Pre-trained Models},
  journal    = {CoRR},
  volume     = {abs/2310.03123},
  year       = {2023},
  url        = {https://doi.org/10.48550/arXiv.2310.03123},
  doi        = {10.48550/ARXIV.2310.03123},
  eprinttype = {arXiv},
  eprint     = {2310.03123},
  timestamp  = {Fri, 10 Nov 2023 21:09:25 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2310-03123.bib},
  tags       = {efficiency, trustworthiness, ip protection, prompt tuning, black-box tuning, zeroth-order optimization, additive tuning, textual prompt tuning},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{geminiteam2023gemini,
  title   = {Gemini: a family of highly capable multimodal models},
  author  = {Gemini Team Google},
  url     = {https://doi.org/10.48550/arXiv.2312.11805},
  journal = {arXiv preprint arXiv:2312.11805},
  year    = {2023}
}

@inproceedings{malladi2023fine,
  title     = {Fine-Tuning Language Models with Just Forward Passes},
  author    = {Sadhika Malladi and Tianyu Gao and Eshaan Nichani and Alex Damian and Jason D. Lee and Danqi Chen and Sanjeev Arora},
  booktitle = {Workshop on Efficient Systems for Foundation Models @ ICML2023},
  year      = {2023},
  url       = {https://openreview.net/forum?id=CcsdvOOzMp}
}

@inproceedings{qin2023federated,
  title     = {Federated Full-Parameter Tuning of Billion-Sized Language Models with Communication Cost under 18 Kilobytes},
  author    = {Qin, Zhen and Chen, Daoyuan and Qian, Bingchen and Ding, Bolin and Li, Yaliang and Deng, Shuiguang},
  booktitle = {Proceedings of the 41th International Conference on Machine Learning},
  venue     = {ICML},
  month     = {jul},
  url       = {https://doi.org/10.48550/arXiv.2312.06353},
  github    = {https://github.com/alibaba/FederatedScope/tree/FedKSeed},
  tags      = {efficiency, zeroth-order optimization},
  year      = {2024}
}

@misc{cai2025feedsignrobustfullparameterfederated,
      title={FeedSign: Robust Full-parameter Federated Fine-tuning of Large Models with Extremely Low Communication Overhead of One Bit},
      author={Zhijie Cai and Haolong Chen and Guangxu Zhu},
      year={2025},
      eprint={2501.17610},
      archivePrefix={arXiv},
      primaryClass={cs.DC},
        tags      = {efficiency, zeroth-order optimization},
      url={https://arxiv.org/abs/2501.17610},
}


@inproceedings{
li2024achievingdimensionfreecommunicationfederated,
title={Achieving Dimension-Free Communication in Federated Learning via Zeroth-Order Optimization},
author={Zhe Li and Bicheng Ying and Zidong Liu and Chaosheng Dong and Haibo Yang},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
venue = {ICLR},
month = {apr},
  tags      = {efficiency, zeroth-order optimization},
url={https://openreview.net/forum?id=omrLHFzC37}
}



@inproceedings{sun2023fedbpt,
  title     = {FedBPT: Efficient Federated Black-box Prompt Tuning for Large Language Models},
  author    = {Sun, Jingwei and Xu, Ziyue and Yin, Hongxu and Yang, Dong and Xu, Daguang and Chen, Yiran and Roth, Holger R},
  booktitle = {Proceedings of the 41th International Conference on Machine Learning},
  doi       = {https://doi.org/10.48550/arXiv.2310.01467},
  url       = {https://doi.org/10.48550/arXiv.2310.01467},
  tags      = {efficiency, trustworthiness, ip protection, , prompt tuning, black-box tuning, additive tuning, textual prompt tuning, zeroth-order optimization},
  venue     = {ICML},
  month     = {jul},
  year      = {2024}
}

@article{9917343,
  author  = {Fang, Wenzhi and Yu, Ziyi and Jiang, Yuning and Shi, Yuanming and Jones, Colin N. and Zhou, Yong},
  journal = {IEEE Transactions on Signal Processing},
  title   = {Communication-Efficient Stochastic Zeroth-Order Optimization for Federated Learning},
  year    = {2022},
  volume  = {70},
  number  = {},
  pages   = {5058-5073},
  doi     = {10.1109/TSP.2022.3214122}
}

@inproceedings{9613620,
  author    = {Li, Zan and Chen, Li},
  booktitle = {2021 13th International Conference on Wireless Communications and Signal Processing (WCSP)},
  title     = {Communication-Efficient Decentralized Zeroth-order Method on Heterogeneous Data},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {1-6},
  doi       = {10.1109/WCSP52459.2021.9613620}
}


@inproceedings{yang2023efficient,
  author    = {Yang, Fu-En and Wang, Chien-Yi and Wang, Yu-Chiang Frank},
  booktitle = {2023 IEEE/CVF International Conference on Computer Vision (ICCV)},
  title     = {Efficient Model Personalization in Federated Learning via Client-Specific Prompt Generation},
  year      = {2023},
  volume    = {},
  number    = {},
  pages     = {19102-19111},
  venue     = {ICCV},
  month     = {oct},
  tags      = {efficiency, additive tuning, prompt tuning, visual prompt tuning},
  url       = {https://ieeexplore.ieee.org/document/10377922},
  doi       = {10.1109/ICCV51070.2023.01755}
}


@inproceedings{charles2023towards,
  title     = {Towards Federated Foundation Models: Scalable Dataset Pipelines for Group-Structured Learning},
  author    = {Zachary Charles and Nicole Elyse Mitchell and Krishna Pillutla and Michael Reneer and Zachary Garrett},
  booktitle = {Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year      = {2023},
  url       = {https://openreview.net/forum?id=EPz1DcdPVE}
}

@article{reed2022generalist,
  title   = {A Generalist Agent},
  author  = {Scott Reed and others},
  journal = {Transactions on Machine Learning Research},
  issn    = {2835-8856},
  year    = {2022},
  url     = {https://openreview.net/forum?id=1ikK0kHjvj},
  note    = {Featured Certification, Outstanding Certification}
}


@inproceedings{dosovitskiy2021an,
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author    = {Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
  booktitle = {International Conference on Learning Representations},
  year      = {2021},
  url       = {https://openreview.net/forum?id=YicbFdNTTy}
}

@inproceedings{kim2021conditional,
  title     = {Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech},
  author    = {Kim, Jaehyeon and Kong, Jungil and Son, Juhee},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning},
  pages     = {5530--5540},
  year      = {2021},
  editor    = {Meila, Marina and Zhang, Tong},
  volume    = {139},
  series    = {Proceedings of Machine Learning Research},
  month     = {18--24 Jul},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v139/kim21f/kim21f.pdf},
  url       = {https://proceedings.mlr.press/v139/kim21f.html}
}

@article{kirillov2023segment,
  title   = {Segment anything},
  author  = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  journal = {arXiv preprint arXiv:2304.02643},
  doi     = {https://doi.org/10.48550/arXiv.2304.02643},
  eprint  = {2304.02643},
  year    = {2023}
}

@inproceedings{Golovin2020Gradientless,
  title     = {Gradientless Descent: High-Dimensional Zeroth-Order Optimization},
  author    = {Daniel Golovin and John Karro and Greg Kochanski and Chansoo Lee and Xingyou Song and Qiuyi Zhang},
  booktitle = {International Conference on Learning Representations},
  year      = {2020},
  url       = {https://openreview.net/forum?id=Skep6TVYDB}
}

@article{10288131,
  author  = {Chaddad, Ahmad and Wu, Yihang and Desrosiers, Christian},
  journal = {IEEE Internet of Things Journal},
  title   = {Federated Learning for Healthcare Applications},
  year    = {2023},
  volume  = {},
  number  = {},
  pages   = {1-1},
  doi     = {10.1109/JIOT.2023.3325822}
}

@inproceedings{zhang-etal-2023-fedlegal,
  title     = {{FEDLEGAL}: The First Real-World Federated Learning Benchmark for Legal {NLP}},
  author    = {Zhang, Zhuo  and
               Hu, Xiangjing  and
               Zhang, Jingyuan  and
               Zhang, Yating  and
               Wang, Hui  and
               Qu, Lizhen  and
               Xu, Zenglin},
  editor    = {Rogers, Anna  and
               Boyd-Graber, Jordan  and
               Okazaki, Naoaki},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = jul,
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.acl-long.193},
  doi       = {10.18653/v1/2023.acl-long.193},
  pages     = {3492--3507},
  github    = {https://github.com/SMILELab-FL/FedLegal},
  venue     = {ACL},
  tags      = {application, domain specific}
}

@inproceedings{shin-etal-2023-fedtherapist,
  title     = {{F}ed{T}herapist: Mental Health Monitoring with User-Generated Linguistic Expressions on Smartphones via Federated Learning},
  author    = {Shin, Jaemin  and
               Yoon, Hyungjun  and
               Lee, Seungjoo  and
               Park, Sungjoon  and
               Liu, Yunxin  and
               Choi, Jinho  and
               Lee, Sung-Ju},
  editor    = {Bouamor, Houda  and
               Pino, Juan  and
               Bali, Kalika},
  booktitle = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  month     = dec,
  year      = {2023},
  address   = {Singapore},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.emnlp-main.734},
  doi       = {10.18653/v1/2023.emnlp-main.734},
  pages     = {11971--11988},
  venue     = {EMNLP},
  tags      = {application, domain specific}
}

@inproceedings{liu-etal-2023-communication,
  title     = {Communication Efficient Federated Learning for Multilingual Neural Machine Translation with Adapter},
  author    = {Liu, Yi  and
               Bi, Xiaohan  and
               Li, Lei  and
               Chen, Sishuo  and
               Yang, Wenkai  and
               Sun, Xu},
  editor    = {Rogers, Anna  and
               Boyd-Graber, Jordan  and
               Okazaki, Naoaki},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2023},
  month     = jul,
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.findings-acl.327},
  doi       = {10.18653/v1/2023.findings-acl.327},
  pages     = {5315--5328},
  name      = {Fed-MNMT},
  tags      = {efficiency, additive tuning, adapter tuning, application, Multilingualism},
  venue     = {ACL},
  github    = {https://github.com/lancopku/FedMNMT}
}

@inproceedings{wu2023leveraging,
  title     = {Leveraging Foundation Models to Improve Lightweight Clients in Federated Learning},
  author    = {Xidong Wu and Wan-Yi Lin and Devin Willmott and Filipe Condessa and Yufei Huang and Zhenzhen Li and Madan Ganesh},
  booktitle = {International Workshop on Federated Learning in the Age of Foundation Models in Conjunction with NeurIPS 2023},
  year      = {2023},
  url       = {https://openreview.net/forum?id=gACRiXPGmM}
}

@article{yu2023bridging,
  title   = {Bridging the Gap Between Foundation Models and Heterogeneous Federated Learning},
  author  = {Yu, Sixing and Mu{\~n}oz, J Pablo and Jannesari, Ali},
  journal = {arXiv preprint arXiv:2310.00247},
  url     = {https://doi.org/10.48550/arXiv.2310.00247},
  year    = {2023}
}

@article{SplitFed,
  author     = {Chandra Thapa and
                Mahawaga Arachchige Pathum Chamikara and
                Seyit Camtepe},
  title      = {SplitFed: When Federated Learning Meets Split Learning},
  journal    = {CoRR},
  volume     = {abs/2004.12088},
  year       = {2020},
  url        = {https://arxiv.org/abs/2004.12088},
  eprinttype = {arXiv},
  eprint     = {2004.12088},
  timestamp  = {Sun, 02 Oct 2022 15:32:00 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2004-12088.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{good-etal-2023-coordinated,
  title     = {Coordinated Replay Sample Selection for Continual Federated Learning},
  author    = {Good, Jack  and
               Majmudar, Jimit  and
               Dupuy, Christophe  and
               Wang, Jixuan  and
               Peris, Charith  and
               Chung, Clement  and
               Zemel, Richard  and
               Gupta, Rahul},
  editor    = {Wang, Mingxuan  and
               Zitouni, Imed},
  booktitle = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track},
  month     = dec,
  year      = {2023},
  address   = {Singapore},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.emnlp-industry.32},
  doi       = {10.18653/v1/2023.emnlp-industry.32},
  pages     = {331--342}
}

@inproceedings{9593126,
  author    = {Seo, Sejin and Ko, Seung-Woo and Park, Jihong and Kim, Seong-Lyun and Bennis, Mehdi},
  booktitle = {2021 IEEE 22nd International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)},
  title     = {Communication-Efficient and Personalized Federated Lottery Ticket Learning},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {581-585},
  doi       = {10.1109/SPAWC51858.2021.9593126}
}

@inproceedings{9708944,
  author    = {Li, Ang and Sun, Jingwei and Wang, Binghui and Duan, Lin and Li, Sicheng and Chen, Yiran and Li, Hai},
  booktitle = {2021 IEEE/ACM Symposium on Edge Computing (SEC)},
  title     = {LotteryFL: Empower Edge Intelligence with Personalized and Communication-Efficient Federated Learning},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {68-79},
  doi       = {10.1145/3453142.3492909}
}

@misc{GDPR,
  title  = {Regulation (EU) 2016/679 of the European Parliament and of the Council},
  author = {GDPR},
  year   = {2016},
  url    = {http://data.europa.eu/eli/reg/2016/679/2016-05-04}
}

@misc{CCPA,
  title  = {California Consumer Privacy Act (CCPA)},
  year   = {2023},
  author = {CCPA},
  url    = {https://oag.ca.gov/privacy/ccpa}
}

@article{zhuang2023foundation,
  title   = {When foundation model meets federated learning: Motivations, challenges, and future directions},
  author  = {Zhuang, Weiming and Chen, Chen and Lyu, Lingjuan},
  journal = {arXiv preprint arXiv:2306.15546},
  tags    = {resources, surveys},
  url     = {https://doi.org/10.48550/arXiv.2306.15546},
  year    = {2023}
}

@inproceedings{yu2023federated,
  title     = {Federated Foundation Models: Privacy-Preserving and Collaborative Learning for Large Models},
  author    = {Yu, Sixing  and
               Munoz, Juan Pablo  and
               Jannesari, Ali},
  editor    = {Calzolari, Nicoletta  and
               Kan, Min-Yen  and
               Hoste, Veronique  and
               Lenci, Alessandro  and
               Sakti, Sakriani  and
               Xue, Nianwen},
  booktitle = {Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},
  month     = may,
  tags      = {resources, surveys},
  year      = {2024},
  address   = {Torino, Italia},
  venue     = {LREC-COLING},
  url       = {https://aclanthology.org/2024.lrec-main.630},
  pages     = {7174--7184}
}


@article{kaplan2020scaling,
  title         = {Scaling Laws for Neural Language Models},
  author        = {Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
  year          = {2020},
  eprint        = {2001.08361},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2001.08361},
  journal       = {arXiv preprint arXiv:2001.08361}
}

@article{gunasekar2023textbook,
  title         = {Textbooks Are All You Need},
  author        = {Suriya Gunasekar and Yi Zhang and Jyoti Aneja and Caio C�sar Teodoro Mendes and Allie Del Giorno and Sivakanth Gopi and Mojan Javaheripi and Piero Kauffmann and Gustavo de Rosa and Olli Saarikivi and Adil Salim and Shital Shah and Harkirat Singh Behl and Xin Wang and S�bastien Bubeck and Ronen Eldan and Adam Tauman Kalai and Yin Tat Lee and Yuanzhi Li},
  year          = {2023},
  eprint        = {2306.11644},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2306.11644},
  journal       = {arXiv preprint arXiv:2306.11644}
}

@inproceedings{cong2023MoE,
  author    = {Cong, Wenyan and Liang, Hanxue and Wang, Peihao and Fan, Zhiwen and Chen, Tianlong and Varma, Mukund and Wang, Yi and Wang, Zhangyang},
  booktitle = {2023 IEEE/CVF International Conference on Computer Vision (ICCV)},
  title     = {Enhancing NeRF akin to Enhancing LLMs: Generalizable NeRF Transformer with Mixture-of-View-Experts},
  year      = {2023},
  volume    = {},
  number    = {},
  pages     = {3170-3181},
  venue     = {ICCV},
  doi       = {10.1109/ICCV51070.2023.00296}
}

@article{chen2023large,
  title         = {When Large Language Models Meet Personalization: Perspectives of Challenges and Opportunities},
  author        = {Jin Chen and Zheng Liu and Xu Huang and Chenwang Wu and Qi Liu and Gangwei Jiang and Yuanhao Pu and Yuxuan Lei and Xiaolong Chen and Xingmei Wang and Defu Lian and Enhong Chen},
  year          = {2023},
  eprint        = {2307.16376},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  url           = {https://arxiv.org/abs/2307.16376},
  journal       = {arXiv preprint arXiv:2307.16376}
}


@article{deng2020model,
  author  = {Deng, Lei and Li, Guoqi and Han, Song and Shi, Luping and Xie, Yuan},
  journal = {Proceedings of the IEEE},
  title   = {Model Compression and Hardware Acceleration for Neural Networks: A Comprehensive Survey},
  year    = {2020},
  volume  = {108},
  number  = {4},
  pages   = {485-532},
  doi     = {10.1109/JPROC.2020.2976475}
}


@article{xu2022adaptive,
  author  = {Xu, Yang and Liao, Yunming and Xu, Hongli and Ma, Zhenguo and Wang, Lun and Liu, Jianchun},
  journal = {IEEE Transactions on Mobile Computing},
  title   = {Adaptive Control of Local Updating and Model Compression for Efficient Federated Learning},
  year    = {2023},
  volume  = {22},
  number  = {10},
  pages   = {5675-5689},
  doi     = {10.1109/TMC.2022.3186936}
}

@article{shen2024large,
  author   = {Shen, Yifei and Shao, Jiawei and Zhang, Xinjie and Lin, Zehong and Pan, Hao and Li, Dongsheng and Zhang, Jun and Letaief, Khaled B.},
  journal  = {IEEE Communications Magazine},
  title    = {Large Language Models Empowered Autonomous Edge AI for Connected Intelligence},
  year     = {2024},
  volume   = {},
  number   = {},
  pages    = {1-7},
  keywords = {Artificial intelligence;Codes;Sensors;Adaptation models;Task analysis;Servers;Computational modeling},
  doi      = {10.1109/MCOM.001.2300550}
}



@inproceedings{woisetschlager2024survey,
  title     = {A Survey on Efficient Federated Learning Methods for Foundation Model Training},
  author    = {Woisetschl{\"a}ger, Herbert and Isenko, Alexander and Wang, Shiqiang and Mayer, Ruben and Jacobsen, Hans-Arno},
  booktitle = {Proceedings of the Thirty-Second International Joint Conference on
               Artificial Intelligence, {IJCAI-24}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  year      = {2024},
  month     = {aug},
  venue     = {IJCAI},
  tags      = {efficiency, resources, surveys},
  url       = {https://www.ijcai.org/proceedings/2024/0919.pdf}
}

@article{xu2024survey,
  title         = {A Survey of Resource-efficient LLM and Multimodal Foundation Models},
  author        = {Mengwei Xu and Wangsong Yin and Dongqi Cai and Rongjie Yi and Daliang Xu and Qipeng Wang and Bingyang Wu and Yihao Zhao and Chen Yang and Shihe Wang and Qiyang Zhang and Zhenyan Lu and Li Zhang and Shangguang Wang and Yuanchun Li and Yunxin Liu and Xin Jin and Xuanzhe Liu},
  year          = {2024},
  eprint        = {2401.08092},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2401.08092},
  journal       = {arXiv preprint arXiv:2401.08092}
}

@article{yang2023federated,
  title     = {Federated Continual Learning via Knowledge Fusion: A Survey},
  issn      = {2326-3865},
  url       = {http://dx.doi.org/10.1109/TKDE.2024.3363240},
  doi       = {10.1109/tkde.2024.3363240},
  journal   = {IEEE Transactions on Knowledge and Data Engineering},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  author    = {Yang, Xin and Yu, Hao and Gao, Xin and Wang, Hao and Zhang, Junbo and Li, Tianrui},
  year      = {2024},
  pages     = {1�20}
}


@article{6790628,
  author  = {Hansen, Nikolaus and Ostermeier, Andreas},
  journal = {Evolutionary Computation},
  title   = {Completely Derandomized Self-Adaptation in Evolution Strategies},
  year    = {2001},
  volume  = {9},
  number  = {2},
  pages   = {159-195},
  doi     = {10.1162/106365601750190398}
}

@article{li2023visual,
  title   = {Visual Prompt Based Personalized Federated Learning},
  author  = {Li, Guanghao and Wu, Wansen and Sun, Yan and Shen, Li and Wu, Baoyuan and Tao, Dacheng},
  journal = {Transactions on Machine Learning Research},
  year    = {2024},
  month   = {feb},
  venue   = {TMLR},
  tags    = {efficiency, additive tuning, prompt tuning, visual prompt tuning},
  github  = {https://github.com/hkgdifyu/pFedPT},
  url     = {https://openreview.net/forum?id=dUVejidXO7}
}


@inproceedings{10205077,
  author    = {Feng, Chun-Mei and Li, Bangjun and Xu, Xinxing and Liu, Yong and Fu, Huazhu and Zuo, Wangmeng},
  booktitle = {2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Learning Federated Visual Prompt in Null Space for MRI Reconstruction},
  year      = {2023},
  month     = {jun},
  volume    = {},
  venue     = {CVPR},
  number    = {},
  pages     = {8064-8073},
  doi       = {10.1109/CVPR52729.2023.00779},
  url       = {https://ieeexplore.ieee.org/document/10205077},
  tags      = {efficiency, additive tuning, application, domain specific, healthcare, MRI Reconstruction, prompt tuning, visual prompt tuning},
  github    = {https://github.com/chunmeifeng/FedPR}
}

@article{yang2023exploring,
  title   = {Exploring One-shot Semi-supervised Federated Learning with A Pre-trained Diffusion Model},
  author  = {Yang, Mingzhao and Su, Shangchao and Li, Bin and Xue, Xiangyang},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year    = {2024}
}



@article{lincy2020early,
  title   = {Early detection of type-2 diabetes using federated learning},
  author  = {Lincy, M and Kowshalya, A Meena},
  journal = {International Journal of Scientific Research in Science, Engineering and Technology},
  volume  = {12},
  pages   = {257--267},
  url     = {https://api.semanticscholar.org/CorpusID:234514776},
  year    = {2020}
}


@article{PANDYA2023102987,
  title   = {Federated learning for smart cities: A comprehensive survey},
  journal = {Sustainable Energy Technologies and Assessments},
  volume  = {55},
  pages   = {102987},
  year    = {2023},
  issn    = {2213-1388},
  doi     = {https://doi.org/10.1016/j.seta.2022.102987},
  url     = {https://www.sciencedirect.com/science/article/pii/S2213138822010359},
  author  = {Sharnil Pandya and Gautam Srivastava and Rutvij Jhaveri and M. Rajasekhara Babu and Sweta Bhattacharya and Praveen Kumar Reddy Maddikunta and Spyridon Mastorakis and Md. Jalil Piran and Thippa Reddy Gadekallu}
}

@article{ramu2022federated,
  title    = {Federated learning enabled digital twins for smart cities: Concepts, recent advances, and future directions},
  journal  = {Sustainable Cities and Society},
  volume   = {79},
  pages    = {103663},
  year     = {2022},
  issn     = {2210-6707},
  doi      = {https://doi.org/10.1016/j.scs.2021.103663},
  url      = {https://www.sciencedirect.com/science/article/pii/S2210670721009264},
  author   = {Swarna Priya Ramu and Parimala Boopalan and Quoc-Viet Pham and Praveen Kumar Reddy Maddikunta and Thien Huynh-The and Mamoun Alazab and Thanh Thi Nguyen and Thippa Reddy Gadekallu},
  keywords = {Digital Twin, Federated Learning, Internet of Things, Virtual replica, Smart city}
}

@article{joshi2022federated,
  author     = {Joshi, Madhura and Pal, Ankit and Sankarasubbu, Malaikannan},
  title      = {Federated Learning for Healthcare Domain - Pipeline, Applications and Challenges},
  year       = {2022},
  issue_date = {October 2022},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {3},
  number     = {4},
  url        = {https://doi.org/10.1145/3533708},
  doi        = {10.1145/3533708},
  journal    = {ACM Trans. Comput. Healthcare},
  month      = {nov},
  articleno  = {40},
  numpages   = {36},
  keywords   = {Federated learning, GDPR, transfer learning}
}


@article{rieke2020future,
  title     = {The future of digital health with federated learning},
  author    = {Rieke, Nicola and Hancox, Jonny and Li, Wenqi and Milletari, Fausto and Roth, Holger R and Albarqouni, Shadi and Bakas, Spyridon and Galtier, Mathieu N and Landman, Bennett A and Maier-Hein, Klaus and others},
  journal   = {NPJ digital medicine},
  volume    = {3},
  number    = {1},
  pages     = {119},
  url       = {https://doi.org/10.1038/s41746-020-00323-1},
  year      = {2020},
  publisher = {Nature Publishing Group UK London}
}

@article{chatterjee2023use,
  title         = {Use of Federated Learning and Blockchain towards Securing Financial Services},
  author        = {Pushpita Chatterjee and Debashis Das and Danda B Rawat},
  year          = {2023},
  eprint        = {2303.12944},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR},
  url           = {https://arxiv.org/abs/2303.12944},
  journal       = {arXiv preprint arXiv:2303.12944}
}

@article{liu2023efficient,
  author         = {Liu, Tao and Wang, Zhi and He, Hui and Shi, Wei and Lin, Liangliang and An, Ran and Li, Chenhao},
  title          = {Efficient and Secure Federated Learning for Financial Applications},
  journal        = {Applied Sciences},
  volume         = {13},
  year           = {2023},
  number         = {10},
  article-number = {5877},
  url            = {https://www.mdpi.com/2076-3417/13/10/5877},
  issn           = {2076-3417},
  doi            = {10.3390/app13105877}
}





@inproceedings{jia2022visual,
  author    = {Jia, Menglin
               and Tang, Luming
               and Chen, Bor-Chun
               and Cardie, Claire
               and Belongie, Serge
               and Hariharan, Bharath
               and Lim, Ser-Nam},
  editor    = {Avidan, Shai
               and Brostow, Gabriel
               and Ciss{\'e}, Moustapha
               and Farinella, Giovanni Maria
               and Hassner, Tal},
  title     = {Visual Prompt Tuning},
  booktitle = {Computer Vision -- ECCV 2022},
  year      = {2022},
  publisher = {Springer Nature Switzerland},
  address   = {Cham},
  pages     = {709--727},
  url       = {https://doi.org/10.1007/978-3-031-19827-4_41},
  isbn      = {978-3-031-19827-4}
}


@article{10.1145/3560815,
  author     = {Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  title      = {Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing},
  year       = {2023},
  issue_date = {September 2023},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {55},
  number     = {9},
  issn       = {0360-0300},
  url        = {https://doi.org/10.1145/3560815},
  doi        = {10.1145/3560815},
  journal    = {ACM Comput. Surv.},
  month      = {jan},
  articleno  = {195},
  numpages   = {35},
  keywords   = {prompting, Pre-trained language models}
}



@article{li2020federated,
  title   = {Federated optimization in heterogeneous networks},
  author  = {Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
  journal = {Proceedings of Machine learning and systems},
  volume  = {2},
  pages   = {429--450},
  year    = {2020}
}



@inproceedings{karimireddy2020scaffold,
  title        = {Scaffold: Stochastic controlled averaging for federated learning},
  author       = {Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
  booktitle    = {International conference on machine learning},
  pages        = {5132--5143},
  year         = {2020},
  organization = {PMLR}
}


@article{hsu2019measuring,
  title   = {Measuring the effects of non-identical data distribution for federated visual classification},
  author  = {Hsu, Tzu-Ming Harry and Qi, Hang and Brown, Matthew},
  journal = {arXiv preprint arXiv:1909.06335},
  year    = {2019}
}

@inproceedings{qiu2024textdriven,
  title     = {Federated Text-driven Prompt Generation for Vision-Language Models},
  author    = {Chen Qiu and Xingyu Li and Chaithanya Kumar Mummadi and Madan Ravi Ganesh and Zhenzhen Li and Lu Peng and Wan-Yi Lin},
  booktitle = {The Twelfth International Conference on Learning Representations},
  year      = {2024},
  month     = {may},
  venue     = {ICLR},
  tags      = {efficiency, additive tuning, prompt tuning, textual-visual prompt tuning},
  url       = {https://openreview.net/forum?id=NW31gAylIm}
}

@inproceedings{zhao2024breaking,
  title     = {Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages},
  author    = {Wanru Zhao and Yihong Chen and Royson Lee and Xinchi Qiu and Yan Gao and Hongxiang Fan and Nicholas Donald Lane},
  booktitle = {The Twelfth International Conference on Learning Representations},
  month     = {may},
  year      = {2024},
  tags      = {application, Multilingualism},
  venue     = {ICLR},
  url       = {https://openreview.net/forum?id=zzqn5G9fjn},
  tags      = {efficiency, additive tuning,  prompt tuning, textual prompt tuning, application, low resource languages, Multilingualism},
  github    = {https://github.com/Ryan0v0/multilingual_borders}
}


@article{su2023federated,
  title   = {Federated Adaptive Prompt Tuning for Multi-Domain Collaborative Learning},
  volume  = {38},
  url     = {https://ojs.aaai.org/index.php/AAAI/article/view/29434},
  doi     = {10.1609/aaai.v38i13.29434},
  number  = {13},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  author  = {Su, Shangchao and Yang, Mingzhao and Li, Bin and Xue, Xiangyang},
  year    = {2024},
  month   = {mar},
  venue   = {AAAI},
  github  = {https://github.com/leondada/FedAPT},
  tags    = {efficiency, additive tuning, prompt tuning, textual-visual prompt tuning, adaptability, domain-centric adaptation, multi-domain adaptation},
  pages   = {15117-15125}
}

@article{feng2023adapterbased,
  author   = {Feng, Xiachong and Feng, Xiaocheng and Du, Xiyuan and Kan, Min-Yen and Qin, Bing},
  journal  = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title    = {Adapter-based Selective Knowledge Distillation for Federated Multi-domain Meeting Summarization},
  year     = {2024},
  volume   = {},
  url      = {https://ieeexplore.ieee.org/document/10557150},
  number   = {},
  venue    = {TASLP},
  month    = {jun},
  pages    = {1-15},
  tags     = {efficiency, additive tuning, adapter tuning, adaptability, domain-centric adaptation, multi-domain adaptation},
  keywords = {Adaptation models;Servers;Federated learning;Data models;Task analysis;Training;Optimization;Meeting Summarization;Federated Learning;Knowledge Distillation;Parameter-efficient Fine-tuning},
  doi      = {10.1109/TASLP.2024.3414313}
}

@article{nguyen2024efficient,
  title         = {Towards Efficient Communication Federated Recommendation System via Low-rank Training},
  author        = {Ngoc-Hieu Nguyen and Tuan-Anh Nguyen and Tuan Nguyen and Vu Tien Hoang and Dung D. Le and Kok-Seng Wong},
  year          = {2024},
  eprint        = {2401.03748},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2401.03748},
  journal       = {arXiv preprint arXiv:2401.03748}
}

@inproceedings{dong-etal-2023-tunable,
  title     = {Tunable Soft Prompts are Messengers in Federated Learning},
  author    = {Dong, Chenhe  and
               Xie, Yuexiang  and
               Ding, Bolin  and
               Shen, Ying  and
               Li, Yaliang},
  editor    = {Bouamor, Houda  and
               Pino, Juan  and
               Bali, Kalika},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2023},
  month     = dec,
  year      = {2023},
  address   = {Singapore},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.findings-emnlp.976},
  doi       = {10.18653/v1/2023.findings-emnlp.976},
  pages     = {14665--14675},
  tags      = {efficiency, additive tuning, prompt tuning, textual prompt tuning},
  venue     = {EMNLP},
  github    = {https://github.com/alibaba/FederatedScope/tree/fedsp/federatedscope/nlp/fedsp}
}

@article{wu2023fedms,
  title         = {FedMS: Federated Learning with Mixture of Sparsely Activated Foundations Models},
  author        = {Panlong Wu and Kangshuo Li and Ting Wang and Fangxin Wang},
  year          = {2023},
  eprint        = {2312.15926},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  tags          = {efficiency, reparameterization-based, LoRA},
  url           = {https://arxiv.org/abs/2312.15926},
  journal       = {arXiv preprint arXiv:2312.15926}
}

@article{10398264,
  author   = {Huang, Xumin and Li, Peichun and Du, Hongyang and Kang, Jiawen and Niyato, Dusit and Kim, Dong In and Wu, Yuan},
  journal  = {IEEE Network},
  title    = {Federated Learning-Empowered AI-Generated Content in Wireless Networks},
  year     = {2024},
  volume   = {},
  number   = {},
  pages    = {1-1},
  keywords = {Data models;Computational modeling;Training;Transformers;Adaptation models;Task analysis;Generative adversarial networks;Federated learning;AIGC;wireless networks;deep learning;stable diffusion},
  doi      = {10.1109/MNET.2024.3353377}
}


@inproceedings{10.1145/3570361.3592505,
  author    = {Cai, Dongqi and Wu, Yaozong and Wang, Shangguang and Lin, Felix Xiaozhu and Xu, Mengwei},
  title     = {Efficient Federated Learning for Modern NLP},
  year      = {2023},
  isbn      = {9781450399906},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3570361.3592505},
  doi       = {10.1145/3570361.3592505},
  booktitle = {Proceedings of the 29th Annual International Conference on Mobile Computing and Networking},
  articleno = {37},
  numpages  = {16},
  keywords  = {federated learning, natural language processing, communication efficiency},
  location  = {Madrid, Spain},
  series    = {ACM MobiCom '23}
}


@inproceedings{10389738,
  author    = {Jia, Junteng and Li, Ke and Malek, Mani and Malik, Kshitiz and Mahadeokar, Jay and Kalinli, Ozlem and Seide, Frank},
  booktitle = {2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  title     = {Joint Federated Learning and Personalization for on-Device ASR},
  year      = {2023},
  volume    = {},
  number    = {},
  venue     = {ASRU},
  month     = {dec},
  pages     = {1-8},
  url       = {https://ieeexplore.ieee.org/document/10389738},
  keywords  = {Degradation;Training;Performance evaluation;Adaptation models;Federated learning;Conferences;Inference algorithms;Federated Learning;Personalization},
  tags      = {personalization, ASR, efficiency, additive tuning,  adapter tuning, application, speech},
  doi       = {10.1109/ASRU57964.2023.10389738}
}

@inproceedings{10389620,
  author    = {Azam, Sheikh Shams and Likhomanenko, Tatiana and Pelikan, Martin and Silovsky, Jan "Honza"},
  booktitle = {2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  title     = {Importance of Smoothness Induced by Optimizers in Fl4Asr: Towards Understanding Federated Learning for End-To-End ASR},
  year      = {2023},
  volume    = {},
  number    = {},
  pages     = {1-8},
  venue     = {ASRU},
  month     = {dec},
  tags      = {personalization, ASR, application, speech},
  url       = {https://ieeexplore.ieee.org/document/10389620},
  doi       = {10.1109/ASRU57964.2023.10389620}
}

@inproceedings{du2024communicationefficient,
  author    = {Du, Yichao and Zhang, Zhirui and Yue, Linan and Huang, Xu and Zhang, Yuqing and Xu, Tong and Xu, Linli and Chen, Enhong},
  booktitle = {ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Communication-Efficient Personalized Federated Learning for Speech-to-Text Tasks},
  year      = {2024},
  venue     = {ICASSP},
  volume    = {},
  url       = {https://ieeexplore.ieee.org/document/10447662},
  number    = {},
  tags      = {efficiency, personalization, speech, ASR, reparameterization-based, LoRA, application, speech},
  month     = {mar},
  pages     = {10001-10005},
  doi       = {10.1109/ICASSP48485.2024.10447662}
}

@inproceedings{
anonymous2025selective,
title={Selective Aggregation for Low-Rank Adaptation in Federated Learning},
author={Pengxin Guo and Shuang Zeng and Yanran Wang and Huijie Fan and Feifei Wang and Liangqiong Qu},
venue = {ICLR},
month = {apr},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
github = {https://github.com/Pengxin-Guo/FedSA-LoRA},
  tags      = {efficiency, personalization, reparameterization-based, LoRA},
url={https://openreview.net/forum?id=iX3uESGdsO}
}


@inproceedings{cho2024heterogeneous,
  title     = {Heterogeneous {L}o{RA} for Federated Fine-tuning of On-Device Foundation Models},
  author    = {Cho, Yae Jee  and
               Liu, Luyang  and
               Xu, Zheng  and
               Fahrezi, Aldi  and
               Joshi, Gauri},
  editor    = {Al-Onaizan, Yaser  and
               Bansal, Mohit  and
               Chen, Yun-Nung},
  booktitle = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  month     = {nov},
  venue     = {EMNLP},
  year      = {2024},
  address   = {Miami, Florida, USA},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.emnlp-main.717},
  tags      = {efficiency, reparameterization-based, LoRA, heterogeneous resource},
  pages     = {12903--12913}
}

@inproceedings{cho2023heterogeneous,
  title     = {Heterogeneous Lo{RA} for Federated Fine-tuning of On-device Foundation Models},
  author    = {Yae Jee Cho and Luyang Liu and Zheng Xu and Aldi Fahrezi and Matt Barnes and Gauri Joshi},
  booktitle = {International Workshop on Federated Learning in the Age of Foundation Models in Conjunction with NeurIPS 2023},
  year      = {2023},
  url       = {https://openreview.net/forum?id=EmV9sGpZ7q}
}

@article{jiang2023lowparameter,
  title         = {Low-Parameter Federated Learning with Large Language Models},
  author        = {Jingang Jiang and Xiangyang Liu and Chenyou Fan},
  year          = {2023},
  eprint        = {2307.13896},
  archiveprefix = {arXiv},
  tags          = {efficiency, reparameterization-based, LoRA},
  primaryclass  = {cs.DC},
  url           = {https://arxiv.org/abs/2307.13896},
  journal       = {arXiv preprint arXiv:2307.13896}
}

@inproceedings{9706703,
  author    = {Yao, Chun-Han and Gong, Boqing and Qi, Hang and Cui, Yin and Zhu, Yukun and Yang, Ming-Hsuan},
  booktitle = {2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  title     = {Federated Multi-Target Domain Adaptation},
  year      = {2022},
  volume    = {},
  number    = {},
  pages     = {1081-1090},
  keywords  = {Performance evaluation;Training;Image segmentation;Costs;Semantics;Distributed databases;Collaborative work;Transfer;Few-shot;Semi- and Un- supervised Learning},
  doi       = {10.1109/WACV51458.2022.00115}
}


@inproceedings{diao2021heterofl,
  title     = {Hetero{\{}FL{\}}: Computation and Communication Efficient Federated Learning for Heterogeneous Clients},
  author    = {Enmao Diao and Jie Ding and Vahid Tarokh},
  booktitle = {International Conference on Learning Representations},
  year      = {2021},
  url       = {https://openreview.net/forum?id=TNkPBBYFkXg}
}

@inproceedings{10204267,
  author    = {Ilhan, Fatih and Su, Gong and Liu, Ling},
  booktitle = {2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {ScaleFL: Resource-Adaptive Federated Learning with Heterogeneous Clients},
  year      = {2023},
  volume    = {},
  number    = {},
  pages     = {24532-24541},
  keywords  = {Training;Adaptation models;Privacy;Federated learning;Computational modeling;Artificial neural networks;Benchmark testing;Others},
  doi       = {10.1109/CVPR52729.2023.02350}
}

@article{9762360,
  author   = {Jiang, Yuang and Wang, Shiqiang and Valls, V�ctor and Ko, Bong Jun and Lee, Wei-Han and Leung, Kin K. and Tassiulas, Leandros},
  journal  = {IEEE Transactions on Neural Networks and Learning Systems},
  title    = {Model Pruning Enables Efficient Federated Learning on Edge Devices},
  year     = {2023},
  volume   = {34},
  number   = {12},
  pages    = {10374-10386},
  keywords = {Training;Computational modeling;Data models;Adaptation models;Collaborative work;Servers;Distributed databases;Efficient training;federated learning (FL);model pruning},
  doi      = {10.1109/TNNLS.2022.3166101}
}




@article{bubeck2023sparks,
  title         = {Sparks of Artificial General Intelligence: Early experiments with GPT-4},
  author        = {S�bastien Bubeck and Varun Chandrasekaran and Ronen Eldan and Johannes Gehrke and Eric Horvitz and Ece Kamar and Peter Lee and Yin Tat Lee and Yuanzhi Li and Scott Lundberg and Harsha Nori and Hamid Palangi and Marco Tulio Ribeiro and Yi Zhang},
  year          = {2023},
  eprint        = {2303.12712},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2303.12712},
  journal       = {arXiv preprint arXiv:2303.12712}
}

@article{li2024position,
  title         = {Position Paper: Assessing Robustness, Privacy, and Fairness in Federated Learning Integrated with Foundation Models},
  author        = {Xi Li and Jiaqi Wang},
  year          = {2024},
  eprint        = {2402.01857},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2402.01857},
  journal       = {arXiv preprint arXiv:2402.01857}
}

@inproceedings{NEURIPS2019_60a6c400,
  author    = {Zhu, Ligeng and Liu, Zhijian and Han, Song},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {Deep Leakage from Gradients},
  url       = {https://proceedings.neurips.cc/paper\_files/paper/2019/file/60a6c4002cc7b29142def8871531281a-Paper.pdf},
  volume    = {32},
  year      = {2019}
}

@inproceedings{NEURIPS2020_c4ede56b,
  author    = {Geiping, Jonas and Bauermeister, Hartmut and Dr\"{o}ge, Hannah and Moeller, Michael},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
  pages     = {16937--16947},
  publisher = {Curran Associates, Inc.},
  title     = {Inverting Gradients - How easy is it to break privacy in federated learning?},
  url       = {https://proceedings.neurips.cc/paper\_files/paper/2020/file/c4ede56bbd98819ae6112b20ac6bf145-Paper.pdf},
  volume    = {33},
  year      = {2020}
}


@article{ji2024ai,
  title         = {AI Alignment: A Comprehensive Survey},
  author        = {Jiaming Ji and Tianyi Qiu and Boyuan Chen and Borong Zhang and Hantao Lou and Kaile Wang and Yawen Duan and Zhonghao He and Jiayi Zhou and Zhaowei Zhang and Fanzhi Zeng and Kwan Yee Ng and Juntao Dai and Xuehai Pan and Aidan O'Gara and Yingshan Lei and Hua Xu and Brian Tse and Jie Fu and Stephen McAleer and Yaodong Yang and Yizhou Wang and Song-Chun Zhu and Yike Guo and Wen Gao},
  year          = {2024},
  eprint        = {2310.19852},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2310.19852},
  journal       = {arXiv preprint arXiv:2310.19852}
}

@article{Ezzeldin_Yan_He_Ferrara_Avestimehr_2023,
  title   = {FairFed: Enabling Group Fairness in Federated Learning},
  volume  = {37},
  url     = {https://ojs.aaai.org/index.php/AAAI/article/view/25911},
  doi     = {10.1609/aaai.v37i6.25911},
  number  = {6},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  author  = {Ezzeldin, Yahya H. and Yan, Shen and He, Chaoyang and Ferrara, Emilio and Avestimehr, A. Salman},
  year    = {2023},
  month   = {Jun.}
}


@inproceedings{xu2024fwdllm,
  author    = {Mengwei Xu and Dongqi Cai and Yaozong Wu and Xiang Li and Shangguang Wang},
  title     = {{FwdLLM}: Efficient Federated Finetuning of Large Language Models with Perturbed Inferences},
  booktitle = {2024 USENIX Annual Technical Conference (USENIX ATC 24)},
  year      = {2024},
  isbn      = {978-1-939133-41-0},
  address   = {Santa Clara, CA},
  github    = {https://github.com/UbiquitousLearning/FwdLLM},
  pages     = {579--596},
  tags      = {efficiency, zeroth-order optimization},
  venue     = {ATC},
  url       = {https://www.usenix.org/conference/atc24/presentation/xu-mengwei},
  publisher = {USENIX Association},
  month     = {jul}
}


@inproceedings{ling2024convergence,
  author    = {Ling, Zhenqing and Chen, Daoyuan and Yao, Liuyi and Li, Yaliang and Shen, Ying},
  title     = {On the Convergence of Zeroth-Order Federated Tuning for Large Language Models},
  year      = {2024},
  isbn      = {9798400704901},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3637528.3671865},
  doi       = {10.1145/3637528.3671865},
  booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages     = {1827–1838},
  numpages  = {12},
  tags      = {efficiency, zeroth-order optimization},
  github    = {https://github.com/alibaba/FederatedScope/tree/FedMeZO},
  keywords  = {convergence analysis, federated learning, large language models, zeroth-order optimization},
  location  = {Barcelona, Spain},
  month     = {aug},
  venue     = {KDD}
}

@article{feng2023does,
  title         = {Does Federated Learning Really Need Backpropagation?},
  author        = {Haozhe Feng and Tianyu Pang and Chao Du and Wei Chen and Shuicheng Yan and Min Lin},
  year          = {2023},
  eprint        = {2301.12195},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2301.12195},
  journal       = {arXiv preprint arXiv:2301.12195}
}

@article{maritan2023fedzen,
  title         = {FedZeN: Towards superlinear zeroth-order federated learning via incremental Hessian estimation},
  author        = {Alessio Maritan and Subhrakanti Dey and Luca Schenato},
  year          = {2023},
  eprint        = {2309.17174},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2309.17174},
  journal       = {arXiv preprint arXiv:2309.17174}
}
@inproceedings{qiu2023zerothorder,
  title     = {Zeroth-Order Methods for Nondifferentiable, Nonconvex, and Hierarchical Federated Optimization},
  author    = {Yuyang Qiu and Uday Shanbhag and Farzad Yousefian},
  booktitle = {Thirty-seventh Conference on Neural Information Processing Systems},
  year      = {2023},
  url       = {https://openreview.net/forum?id=46x3zvYCyQ}
}


@inproceedings{NEURIPS2020_a1d4c20b,
  author    = {He, Chaoyang and Annavaram, Murali and Avestimehr, Salman},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
  pages     = {14068--14080},
  publisher = {Curran Associates, Inc.},
  title     = {Group Knowledge Transfer: Federated Learning of Large CNNs at the Edge},
  url       = {https://proceedings.neurips.cc/paper\_files/paper/2020/file/a1d4c20b182ad7137ab3606f0e3fc8a4-Paper.pdf},
  volume    = {33},
  year      = {2020}
}

@article{10.1145/3510033,
  author     = {Tian, Yuanyishu and Wan, Yao and Lyu, Lingjuan and Yao, Dezhong and Jin, Hai and Sun, Lichao},
  title      = {FedBERT: When Federated Learning Meets Pre-training},
  year       = {2022},
  issue_date = {August 2022},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {13},
  number     = {4},
  issn       = {2157-6904},
  url        = {https://doi.org/10.1145/3510033},
  doi        = {10.1145/3510033},
  journal    = {ACM Trans. Intell. Syst. Technol.},
  month      = {aug},
  articleno  = {66},
  numpages   = {26},
  keywords   = {Federated learning, pre-training, BERT, NLP}
}

@inproceedings{wang-etal-2023-federated,
  title     = {Federated Domain Adaptation for Named Entity Recognition via Distilling with Heterogeneous Tag Sets},
  author    = {Wang, Rui  and
               Yu, Tong  and
               Wu, Junda  and
               Zhao, Handong  and
               Kim, Sungchul  and
               Zhang, Ruiyi  and
               Mitra, Subrata  and
               Henao, Ricardo},
  editor    = {Rogers, Anna  and
               Boyd-Graber, Jordan  and
               Okazaki, Naoaki},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2023},
  month     = jul,
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.findings-acl.470},
  doi       = {10.18653/v1/2023.findings-acl.470},
  pages     = {7449--7463},
  venue     = {ACL},
  tags      = {adaptability, domain-centric adaptation}
}

@article{tsouvalas2023federated,
  title         = {Federated Fine-Tuning of Foundation Models via Probabilistic Masking},
  author        = {Vasileios Tsouvalas and Yuki Asano and Aaqib Saeed},
  year          = {2023},
  eprint        = {2311.17299},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2311.17299},
  journal       = {arXiv preprint arXiv:2311.17299}
}


@inproceedings{pmlr-v108-reisizadeh20a,
  title     = {FedPAQ: A Communication-Efficient Federated Learning Method with Periodic Averaging and Quantization},
  author    = {Reisizadeh, Amirhossein and Mokhtari, Aryan and Hassani, Hamed and Jadbabaie, Ali and Pedarsani, Ramtin},
  booktitle = {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  pages     = {2021--2031},
  year      = {2020},
  editor    = {Chiappa, Silvia and Calandra, Roberto},
  volume    = {108},
  series    = {Proceedings of Machine Learning Research},
  month     = {26--28 Aug},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v108/reisizadeh20a/reisizadeh20a.pdf},
  url       = {https://proceedings.mlr.press/v108/reisizadeh20a.html}
}

@article{gupta2023quantization,
  title   = {Quantization Robust Federated Learning for Efficient Inference on Heterogeneous Devices},
  author  = {Kartik Gupta and Marios Fournarakis and Matthias Reisser and Christos Louizos and Markus Nagel},
  journal = {Transactions on Machine Learning Research},
  issn    = {2835-8856},
  year    = {2023},
  url     = {https://openreview.net/forum?id=lvevdX6bxm},
  note    = {}
}

@inproceedings{anonymous-acl24-arr,
  title     = {Personalized Federated Learning for Text Classification with Gradient-Free Prompt Tuning},
  author    = {Rui, Wang and Tong, Yu and Ruiyi, Zhang and Sungchul, Kim and Ryan A., Rossi and Handong, Zhao
               and Junda, Wu and Subrata, Mitra and Lina, Yao and Ricardo, Henao},
  booktitle = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  year      = {2024},
  venue     = {NAACL},
  month     = {jun},
  tags      = {efficiency, additive tuning, prompt tuning, trustworthiness, ip protection, black-box tuning, textual prompt tuning, zeroth-order optimization},
  url       = {https://aclanthology.org/2024.findings-naacl.286.pdf}
}



@article{10.1145/3494834.3500240,
  author     = {Bonawitz, Kallista and Kairouz, Peter and McMahan, Brendan and Ramage, Daniel},
  title      = {Federated Learning and Privacy: Building privacy-preserving systems for machine learning and data science on decentralized data},
  year       = {2021},
  issue_date = {September-October 2021},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {19},
  number     = {5},
  issn       = {1542-7730},
  url        = {https://doi.org/10.1145/3494834.3500240},
  doi        = {10.1145/3494834.3500240},
  journal    = {Queue},
  month      = {nov},
  pages      = {87-114},
  numpages   = {28}
}

@inproceedings{li-etal-2023-multi-step,
  title     = {Multi-step Jailbreaking Privacy Attacks on {C}hat{GPT}},
  author    = {Li, Haoran  and
               Guo, Dadi  and
               Fan, Wei  and
               Xu, Mingshi  and
               Huang, Jie  and
               Meng, Fanpu  and
               Song, Yangqiu},
  editor    = {Bouamor, Houda  and
               Pino, Juan  and
               Bali, Kalika},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2023},
  month     = dec,
  year      = {2023},
  address   = {Singapore},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.findings-emnlp.272},
  doi       = {10.18653/v1/2023.findings-emnlp.272},
  pages     = {4138--4153}
}

@inproceedings{huang-etal-2022-large,
  title     = {Are Large Pre-Trained Language Models Leaking Your Personal Information?},
  author    = {Huang, Jie  and
               Shao, Hanyin  and
               Chang, Kevin Chen-Chuan},
  editor    = {Goldberg, Yoav  and
               Kozareva, Zornitsa  and
               Zhang, Yue},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2022},
  month     = dec,
  year      = {2022},
  address   = {Abu Dhabi, United Arab Emirates},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.findings-emnlp.148},
  doi       = {10.18653/v1/2022.findings-emnlp.148},
  pages     = {2038--2047}
}


@article{10018261,
  author   = {Li, Shenghui and Ngai, Edith C.-H. and Voigt, Thiemo},
  journal  = {IEEE Transactions on Big Data},
  title    = {An Experimental Study of Byzantine-Robust Aggregation Schemes in Federated Learning},
  year     = {2024},
  volume   = {10},
  number   = {6},
  pages    = {975-988},
  url      = {https://ieeexplore.ieee.org/document/10018261},
  keywords = {Servers;Training;Robustness;Federated learning;Optimization;Computational modeling;Performance evaluation;Byzantine attacks;distributed learning;federated learning;neural networks;robustness},
  doi      = {10.1109/TBDATA.2023.3237397}
}


@article{kang2024grounding,
  title         = {Grounding Foundation Models through Federated Transfer Learning: A General Framework},
  author        = {Yan Kang and Tao Fan and Hanlin Gu and Xiaojin Zhang and Lixin Fan and Qiang Yang},
  year          = {2024},
  eprint        = {2311.17431},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2311.17431},
  journal       = {arXiv preprint arXiv:2311.17431}
}

@article{9847383,
  author   = {Li, Bowen and Fan, Lixin and Gu, Hanlin and Li, Jie and Yang, Qiang},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title    = {FedIPR: Ownership Verification for Federated Deep Neural Network Models},
  year     = {2023},
  volume   = {45},
  number   = {4},
  pages    = {4521-4536},
  keywords = {Watermarking;Collaborative work;Data models;Computational modeling;Training;Intellectual property;Training data;Model IPR protection;ownership verification;federated learning;model watermarking;backdoor training},
  doi      = {10.1109/TPAMI.2022.3195956}
}


@inproceedings{9603498,
  author    = {Tekgul, Buse G. A. and Xia, Yuxi and Marchal, Samuel and Asokan, N.},
  booktitle = {2021 40th International Symposium on Reliable Distributed Systems (SRDS)},
  title     = {WAFFLE: Watermarking in Federated Learning},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {310-320},
  keywords  = {Training;Reverse engineering;Training data;Process control;Watermarking;Collaborative work;Data models;Federated learning;ownership demonstration;watermarking;deep learning},
  doi       = {10.1109/SRDS53918.2021.00038}
}

@inproceedings{217591,
  author    = {Yossi Adi and Carsten Baum and Moustapha Cisse and Benny Pinkas and Joseph Keshet},
  title     = {Turning Your Weakness Into a Strength: Watermarking Deep Neural Networks by Backdooring},
  booktitle = {27th USENIX Security Symposium (USENIX Security 18)},
  year      = {2018},
  isbn      = {978-1-939133-04-5},
  address   = {Baltimore, MD},
  pages     = {1615--1631},
  url       = {https://www.usenix.org/conference/usenixsecurity18/presentation/adi},
  publisher = {USENIX Association},
  month     = aug
}

@inproceedings{yu2023who,
  title     = {Who Leaked the Model? Tracking {IP} Infringers in Accountable Federated Learning},
  author    = {Shuyang Yu and Junyuan Hong and Yi Zeng and Fei Wang and Ruoxi Jia and Jiayu Zhou},
  booktitle = {NeurIPS 2023 Workshop on Regulatable ML},
  year      = {2023},
  url       = {https://openreview.net/forum?id=qhP1aHHyeA}
}

@inproceedings{NEURIPS2022_35b5c175,
  author    = {Gupta, Samyak and Huang, Yangsibo and Zhong, Zexuan and Gao, Tianyu and Li, Kai and Chen, Danqi},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
  pages     = {8130--8143},
  publisher = {Curran Associates, Inc.},
  title     = {Recovering Private Text in Federated Learning of Language Models},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2022/file/35b5c175e139bff5f22a5361270fce87-Paper-Conference.pdf},
  volume    = {35},
  venue     = {NeurIPS},
  month     = {nov},
  tags      = {trustworthiness, differential privacy, privacy preservation, privacy attack},
  github    = {https://github.com/Princeton-SysML/FILM},
  year      = {2022}
}


@inproceedings{
anonymous2025privacypreserving,
title={Privacy-Preserving Personalized Federated Prompt Learning for Multimodal Large Language Models},
author={Linh Tran and Wei Sun and Stacy Patterson and Ana Milanova},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
venue = {ICLR},
month = {apr},
  tags    = {efficiency, additive tuning, prompt tuning, textual-visual prompt tuning, trustworthiness, differential privacy, privacy preservation, privacy-preserving techniques},
url={https://openreview.net/forum?id=Equ277PBN0}
}

@inproceedings{10.5555/3692070.3692836,
author = {Hou, Charlie and Shrivastava, Akshat and Zhan, Hongyuan and Conway, Rylan and Le, Trang and Sagar, Adithya and Fanti, Giulia and Lazar, Daniel},
title = {PrE-Text: training language models on private federated data in the age of LLMs},
year = {2024},
publisher = {JMLR.org},
booktitle = {Proceedings of the 41st International Conference on Machine Learning},
articleno = {766},
numpages = {19},
url = {https://icml.cc/virtual/2024/poster/35060},
location = {Vienna, Austria},
venue = {ICML},
month = {jul},
  tags      = {trustworthiness, differential privacy, privacy preservation, privacy attack},
github = {https://github.com/houcharlie/PrE-Text},
series = {ICML'24}
}

@inproceedings{pmlr-v238-vu24a,
  title     = { Analysis of Privacy Leakage in Federated Large Language Models },
  author    = {Vu, Minh and Nguyen, Truc and Jeter, Tre' and T. Thai, My},
  booktitle = {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},
  pages     = {1423--1431},
  year      = {2024},
  editor    = {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},
  volume    = {238},
  series    = {Proceedings of Machine Learning Research},
  month     = {may},
  venue     = {AISTATS},
  github    = {https://github.com/vunhatminh/FL_Attacks},
  publisher = {PMLR},
  tags      = {trustworthiness, differential privacy, privacy preservation, privacy attack},
  pdf       = {https://proceedings.mlr.press/v238/vu24a/vu24a.pdf},
  url       = {https://proceedings.mlr.press/v238/vu24a.html}
}

@inproceedings{xu-etal-2023-federated,
  title     = {Federated Learning of Gboard Language Models with Differential Privacy},
  author    = {Xu, Zheng  and
               Zhang, Yanxiang  and
               Andrew, Galen  and
               Choquette, Christopher  and
               Kairouz, Peter  and
               Mcmahan, Brendan  and
               Rosenstock, Jesse  and
               Zhang, Yuanbo},
  editor    = {Sitaram, Sunayana  and
               Beigman Klebanov, Beata  and
               Williams, Jason D},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 5: Industry Track)},
  month     = jul,
  year      = {2023},
  venue     = {ACL},
  tags      = {trustworthiness, differential privacy, privacy preservation, privacy-preserving techniques},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.acl-industry.60},
  doi       = {10.18653/v1/2023.acl-industry.60},
  pages     = {629--639}
}


@inproceedings{sun2024improving,
  title     = {Improving Lo{RA} in Privacy-preserving Federated Learning},
  author    = {Youbang Sun and Zitao Li and Yaliang Li and Bolin Ding},
  booktitle = {The Twelfth International Conference on Learning Representations},
  venue     = {ICLR},
  year      = {2024},
  month     = {may},
  tags      = {efficiency, LoRA, reparameterization-based, trustworthiness, differential privacy, privacy preservation, privacy-preserving techniques},
  url       = {https://openreview.net/forum?id=NLPzL6HWNl}
}


@article{liu2023differentially,
  title         = {Differentially Private Low-Rank Adaptation of Large Language Model Using Federated Learning},
  author        = {Xiao-Yang Liu and Rongyi Zhu and Daochen Zha and Jiechao Gao and Shan Zhong and Meikang Qiu},
  year          = {2023},
  eprint        = {2312.17493},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2312.17493},
  tags          = {efficiency, LoRA, reparameterization-based, trustworthiness, differential privacy, privacy preservation, privacy-preserving techniques},
  journal       = {arXiv preprint arXiv:2312.17493}
}

@article{nagy2023privacy,
  title     = {Privacy-preserving Federated Learning and its application to natural language processing},
  author    = {Nagy, Bal{\'a}zs and Heged{\H{u}}s, Istv{\'a}n and S{\'a}ndor, No{\'e}mi and Egedi, Bal{\'a}zs and Mehmood, Haaris and Saravanan, Karthikeyan and L{\'o}ki, G{\'a}bor and Kiss, {\'A}kos},
  journal   = {Knowledge-Based Systems},
  volume    = {268},
  pages     = {110475},
  year      = {2023},
  publisher = {Elsevier}
}

@article{10.1145/3460427,
  author     = {Yin, Xuefei and Zhu, Yanming and Hu, Jiankun},
  title      = {A Comprehensive Survey of Privacy-preserving Federated Learning: A Taxonomy, Review, and Future Directions},
  year       = {2021},
  issue_date = {July 2022},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {54},
  number     = {6},
  issn       = {0360-0300},
  url        = {https://doi.org/10.1145/3460427},
  doi        = {10.1145/3460427},
  journal    = {ACM Comput. Surv.},
  month      = {jul},
  articleno  = {131},
  numpages   = {36},
  keywords   = {Privacy-preserving federated learning, anonymization techniques, cryptographic encryption, data privacy, federated transfer learning, horizontal federated learning, perturbation techniques, vertical federated learning}
}


@article{babakniya2023revisiting,
  title   = {Revisiting Sparsity Hunting in Federated Learning: Why does Sparsity Consensus Matter?},
  author  = {Sara Babakniya and Souvik Kundu and Saurav Prakash and Yue Niu and Salman Avestimehr},
  journal = {Transactions on Machine Learning Research},
  issn    = {2835-8856},
  year    = {2023},
  url     = {https://openreview.net/forum?id=iHyhdpsnyi},
  note    = {}
}


@article{9069945,
  author   = {Wei, Kang and Li, Jun and Ding, Ming and Ma, Chuan and Yang, Howard H. and Farokhi, Farhad and Jin, Shi and Quek, Tony Q. S. and Vincent Poor, H.},
  journal  = {IEEE Transactions on Information Forensics and Security},
  title    = {Federated Learning With Differential Privacy: Algorithms and Performance Analysis},
  year     = {2020},
  volume   = {15},
  number   = {},
  pages    = {3454-3469},
  keywords = {Convergence;Privacy;Servers;Training;Analytical models;Distributed databases;Federated learning;differential privacy;convergence performance;information leakage;client selection},
  doi      = {10.1109/TIFS.2020.2988575}
}

@article{shin2023fedsplitx,
  title         = {FedSplitX: Federated Split Learning for Computationally-Constrained Heterogeneous Clients},
  author        = {Jiyun Shin and Jinhyun Ahn and Honggu Kang and Joonhyuk Kang},
  year          = {2023},
  eprint        = {2310.14579},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2310.14579},
  journal       = {arXiv preprint arXiv:2310.14579}
}

@article{Thapa_MahawagaArachchige_Camtepe_Sun_2022,
  title   = {SplitFed: When Federated Learning Meets Split Learning},
  volume  = {36},
  url     = {https://ojs.aaai.org/index.php/AAAI/article/view/20825},
  doi     = {10.1609/aaai.v36i8.20825},
  number  = {8},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  author  = {Thapa, Chandra and Mahawaga Arachchige, Pathum Chamikara and Camtepe, Seyit and Sun, Lichao},
  year    = {2022},
  month   = {Jun.},
  pages   = {8485-8493}
}

@article{9660377,
  author  = {Shah, Suhail Mohmad and Lau, Vincent K. N.},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  title   = {Model Compression for Communication Efficient Federated Learning},
  year    = {2023},
  volume  = {34},
  number  = {9},
  pages   = {5937-5951},
  doi     = {10.1109/TNNLS.2021.3131614}
}

@inproceedings{reddi2020adaptive,
  title     = {Adaptive Federated Optimization},
  author    = {Sashank J. Reddi and Zachary Charles and Manzil Zaheer and Zachary Garrett and Keith Rush and Jakub Kone{\v{c}}n{\'y} and Sanjiv Kumar and Hugh Brendan McMahan},
  booktitle = {International Conference on Learning Representations},
  year      = {2021},
  url       = {https://openreview.net/forum?id=LkFG3lB13U5}
}

@inproceedings{MLSYS2020_1f5fe839,
  author    = {Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
  booktitle = {Proceedings of Machine Learning and Systems},
  editor    = {I. Dhillon and D. Papailiopoulos and V. Sze},
  pages     = {429--450},
  title     = {Federated Optimization in Heterogeneous Networks},
  url       = {https://proceedings.mlsys.org/paper\_files/paper/2020/file/1f5fe83998a09396ebe6477d9475ba0c-Paper.pdf},
  volume    = {2},
  year      = {2020}
}

@inproceedings{acar2021federated,
  title     = {Federated Learning Based on Dynamic Regularization},
  author    = {Durmus Alp Emre Acar and Yue Zhao and Ramon Matas and Matthew Mattina and Paul Whatmough and Venkatesh Saligrama},
  booktitle = {International Conference on Learning Representations},
  year      = {2021},
  url       = {https://openreview.net/forum?id=B7v4QMR6Z9w}
}

@article{li2024personal,
  title         = {Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security},
  author        = {Yuanchun Li and Hao Wen and Weijun Wang and Xiangyu Li and Yizhen Yuan and Guohong Liu and Jiacheng Liu and Wenxing Xu and Xiang Wang and Yi Sun and Rui Kong and Yile Wang and Hanfei Geng and Jian Luan and Xuefeng Jin and Zilong Ye and Guanjing Xiong and Fan Zhang and Xiang Li and Mengwei Xu and Zhijun Li and Peng Li and Yang Liu and Ya-Qin Zhang and Yunxin Liu},
  year          = {2024},
  eprint        = {2401.05459},
  archiveprefix = {arXiv},
  primaryclass  = {cs.HC},
  url           = {https://arxiv.org/abs/2401.05459},
  journal       = {arXiv preprint arXiv:2401.05459}
}

@inproceedings{10386351,
  author    = {Gan, Wensheng and Wan, Shicheng and Yu, Philip S.},
  booktitle = {2023 IEEE International Conference on Big Data (BigData)},
  title     = {Model-as-a-Service (MaaS): A Survey},
  year      = {2023},
  volume    = {},
  number    = {},
  pages     = {4636-4645},
  keywords  = {Surveys;Industries;Training;Cloud computing;Generative AI;Computational modeling;Organizations;foundation models;artificial intelligence;generative AI;Model-as-a-Service;APIs},
  doi       = {10.1109/BigData59044.2023.10386351}
}

@article{wu2023aigenerated,
  title         = {AI-Generated Content (AIGC): A Survey},
  author        = {Jiayang Wu and Wensheng Gan and Zefeng Chen and Shicheng Wan and Hong Lin},
  year          = {2023},
  eprint        = {2304.06632},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2304.06632},
  journal       = {arXiv preprint arXiv:2304.06632}
}


@article{10398474,
  author   = {Xu, Minrui and Du, Hongyang and Niyato, Dusit and Kang, Jiawen and Xiong, Zehui and Mao, Shiwen and Han, Zhu and Jamalipour, Abbas and Kim, Dong In and Shen, Xuemin and Leung, Victor C. M. and Poor, H. Vincent},
  journal  = {IEEE Communications Surveys \& Tutorials},
  title    = {Unleashing the Power of Edge-Cloud Generative AI in Mobile Networks: A Survey of AIGC Services},
  year     = {2024},
  volume   = {},
  number   = {},
  pages    = {1-1},
  keywords = {Computational modeling;Servers;Biological system modeling;Artificial intelligence;Generative AI;Surveys;Mobile handsets;AIGC;Generative AI;Mobile edge networks;Communication and Networking;AI training and inference;Internet technology},
  doi      = {10.1109/COMST.2024.3353265}
}

@article{cao2023comprehensive,
  title         = {A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT},
  author        = {Yihan Cao and Siyu Li and Yixin Liu and Zhiling Yan and Yutong Dai and Philip S. Yu and Lichao Sun},
  year          = {2023},
  eprint        = {2303.04226},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2303.04226},
  journal       = {arXiv preprint arXiv:2303.04226}
}

@article{zhao2024retrievalaugmented,
  title         = {Retrieval-Augmented Generation for AI-Generated Content: A Survey},
  author        = {Penghao Zhao and Hailin Zhang and Qinhan Yu and Zhengren Wang and Yunteng Geng and Fangcheng Fu and Ling Yang and Wentao Zhang and Bin Cui},
  year          = {2024},
  eprint        = {2402.19473},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2402.19473},
  journal       = {arXiv preprint arXiv:2402.19473}
}


@inproceedings{ye2024openfedllm,
  author    = {Ye, Rui and Wang, Wenhao and Chai, Jingyi and Li, Dihan and Li, Zexi and Xu, Yinda and Du, Yaxin and Wang, Yanfeng and Chen, Siheng},
  title     = {OpenFedLLM: Training Large Language Models on Decentralized Private Data via Federated Learning},
  year      = {2024},
  isbn      = {9798400704901},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3637528.3671582},
  doi       = {10.1145/3637528.3671582},
  booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages     = {6137–6147},
  numpages  = {11},
  tags      = {resource, code, library},
  keywords  = {federated learning, instruction tuning, large language models, value alignment},
  location  = {Barcelona, Spain},
  month     = {aug},
  venue     = {KDD}
}

@article{kuang2023federatedscopellm,
  title         = {FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning},
  author        = {Weirui Kuang and Bingchen Qian and Zitao Li and Daoyuan Chen and Dawei Gao and Xuchen Pan and Yuexiang Xie and Yaliang Li and Bolin Ding and Jingren Zhou},
  year          = {2023},
  eprint        = {2309.00363},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2309.00363},
  journal       = {arXiv preprint arXiv:2309.00363}
}


@article{fan2023fatellm,
  title         = {FATE-LLM: A Industrial Grade Federated Learning Framework for Large Language Models},
  author        = {Tao Fan and Yan Kang and Guoqiang Ma and Weijing Chen and Wenbin Wei and Lixin Fan and Qiang Yang},
  year          = {2023},
  eprint        = {2310.10049},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2310.10049},
  journal       = {arXiv preprint arXiv:2310.10049}
}

@article{han2024fedmlsecurity,
  title         = {FedMLSecurity: A Benchmark for Attacks and Defenses in Federated Learning and Federated LLMs},
  author        = {Shanshan Han and Baturalp Buyukates and Zijian Hu and Han Jin and Weizhao Jin and Lichao Sun and Xiaoyang Wang and Wenxuan Wu and Chulin Xie and Yuhang Yao and Kai Zhang and Qifan Zhang and Yuhui Zhang and Carlee Joe-Wong and Salman Avestimehr and Chaoyang He},
  year          = {2024},
  eprint        = {2306.04959},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR},
  url           = {https://arxiv.org/abs/2306.04959},
  journal       = {arXiv preprint arXiv:2306.04959}
}

@misc{fedllm,
  title  = {FedLLM},
  author = {FedML},
  year   = {2023},
  url    = {https://blog.fedml.ai/releasing-fedllm-build-your-own-large-language-models-on-proprietary-data-using-the-fedml-platform/}
}

@misc{Alpaca-LoRA,
  title  = {Alpaca-LoRA},
  author = {Eric Wang},
  year   = {2023},
  url    = {https://github.com/tloen/alpaca-lora}
}

@article{collins2023profit,
  title         = {Profit: Benchmarking Personalization and Robustness Trade-off in Federated Prompt Tuning},
  author        = {Liam Collins and Shanshan Wu and Sewoong Oh and Khe Chai Sim},
  year          = {2023},
  eprint        = {2310.04627},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2310.04627},
  journal       = {arXiv preprint arXiv:2310.04627}
}


@article{zhao2024llmbased,
  title         = {LLM-based Federated Recommendation},
  author        = {Jujia Zhao and Wenjie Wang and Chen Xu and Zhaochun Ren and See-Kiong Ng and Tat-Seng Chua},
  year          = {2024},
  eprint        = {2402.09959},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  url           = {https://arxiv.org/abs/2402.09959},
  journal       = {arXiv preprint arXiv:2402.09959},
  tags          = {application, Recommendation Systems}
}

@article{li2024navigating,
  title         = {Navigating the Future of Federated Recommendation Systems with Foundation Models},
  author        = {Zhiwei Li and Guodong Long},
  year          = {2024},
  eprint        = {2406.00004},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  tags          = {application, Recommendation Systems},
  url           = {https://arxiv.org/abs/2406.00004},
  journal       = {arXiv preprint arXiv:2406.00004}
}

@article{zhang2024transfr,
  title         = {TransFR: Transferable Federated Recommendation with Pre-trained Language Models},
  author        = {Honglei Zhang and He Liu and Haoxuan Li and Yidong Li},
  year          = {2024},
  eprint        = {2402.01124},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  url           = {https://arxiv.org/abs/2402.01124},
  journal       = {arXiv preprint arXiv:2402.01124},
  tags          = {application, Recommendation Systems}
}

@article{roth2024empowering,
  title         = {Empowering Federated Learning for Massive Models with NVIDIA FLARE},
  author        = {Holger R. Roth and Ziyue Xu and Yuan-Ting Hsieh and Adithya Renduchintala and Isaac Yang and Zhihong Zhang and Yuhong Wen and Sean Yang and Kevin Lu and Kristopher Kersten and Camir Ricketts and Daguang Xu and Chester Chen and Yan Cheng and Andrew Feng},
  year          = {2024},
  eprint        = {2402.07792},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2402.07792},
  journal       = {arXiv preprint arXiv:2402.07792}
}

@article{yang2023interpretable,
  title         = {Towards Interpretable Mental Health Analysis with Large Language Models},
  author        = {Kailai Yang and Shaoxiong Ji and Tianlin Zhang and Qianqian Xie and Ziyan Kuang and Sophia Ananiadou},
  year          = {2023},
  eprint        = {2304.03347},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2304.03347},
  journal       = {arXiv preprint arXiv:2304.03347}
}

@article{doi:10.1126/sciadv.adg7865,
  author  = {Vijil Chenthamarakshan  and Samuel C. Hoffman  and C. David Owen  and Petra Lukacik  and Claire Strain-Damerell  and Daren Fearon  and Tika R. Malla  and Anthony Tumber  and Christopher J. Schofield  and Helen M.E. Duyvesteyn  and Wanwisa Dejnirattisai  and Loic Carrique  and Thomas S. Walter  and Gavin R. Screaton  and Tetiana Matviiuk  and Aleksandra Mojsilovic  and Jason Crain  and Martin A. Walsh  and David I. Stuart  and Payel Das },
  title   = {Accelerating drug target inhibitor discovery with a deep generative foundation model},
  journal = {Science Advances},
  volume  = {9},
  number  = {25},
  pages   = {eadg7865},
  year    = {2023},
  doi     = {10.1126/sciadv.adg7865},
  url     = {https://www.science.org/doi/abs/10.1126/sciadv.adg7865},
  eprint  = {https://www.science.org/doi/pdf/10.1126/sciadv.adg7865}
}

@article{panagoulias2024evaluating,
  title         = {Evaluating LLM -- Generated Multimodal Diagnosis from Medical Images and Symptom Analysis},
  author        = {Dimitrios P. Panagoulias and Maria Virvou and George A. Tsihrintzis},
  year          = {2024},
  eprint        = {2402.01730},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2402.01730},
  journal       = {arXiv preprint arXiv:2402.01730}
}

@article{chen2023federated,
  title         = {Federated Large Language Model: A Position Paper},
  author        = {Chaochao Chen and Xiaohua Feng and Jun Zhou and Jianwei Yin and Xiaolin Zheng},
  year          = {2023},
  eprint        = {2307.08925},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2307.08925},
  journal       = {arXiv preprint arXiv:2307.08925}
}


@inproceedings{chu2024send,
  author    = {Chu, Yun-Wei and Han, Dong-Jun and Brinton, Christopher G.},
  title     = {Only Send What You Need: Learning to Communicate Efficiently in Federated Multilingual Machine Translation},
  year      = {2024},
  month     = {may},
  isbn      = {9798400701726},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3589335.3651931},
  doi       = {10.1145/3589335.3651931},
  booktitle = {Companion Proceedings of the ACM on Web Conference 2024},
  pages     = {1548-1557},
  numpages  = {10},
  keywords  = {federated learning, machine translation},
  location  = {<conf-loc>, <city>Singapore</city>, <country>Singapore</country>, </conf-loc>},
  venue     = {WWW},
  tags      = {Application, Machine Translation, Multilingualism, efficiency, selective tuning, sparsification}
}

@misc{zhu2024promotingdatamodelprivacy,
  title         = {Promoting Data and Model Privacy in Federated Learning through Quantized LoRA},
  author        = {JianHao Zhu and Changze Lv and Xiaohua Wang and Muling Wu and Wenhao Liu and Tianlong Li and Zixuan Ling and Cenyuan Zhang and Xiaoqing Zheng and Xuanjing Huang},
  year          = {2024},
  eprint        = {2406.10976},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  tags          = {efficiency, sparsification, LoRA, reparameterization-based, trustworthiness, privacy preservation, privacy-preserving techniques},
  url           = {https://arxiv.org/abs/2406.10976}
}


@inproceedings{anonymous-naacl24-arr,
  title     = {Generalizable Multilingual Hate Speech Detection on Low Resource Indian Languages using Fair Selection in Federated Learning},
  author    = {Akshay, Singh and Rahul, Thakur},
  booktitle = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  year      = {2024},
  venue     = {NAACL},
  month     = {jun},
  url       = {https://2024.naacl.org/program/accepted_papers/},
  tags      = {Application, Multilingualism}
}


@inproceedings{NEURIPS2020_92d1e1eb,
  author    = {Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
  pages     = {12449--12460},
  publisher = {Curran Associates, Inc.},
  title     = {wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2020/file/92d1e1eb1cd6f9fba3227870bb6d7f07-Paper.pdf},
  volume    = {33},
  year      = {2020}
}


@inproceedings{pmlr-v202-radford23a,
  title     = {Robust Speech Recognition via Large-Scale Weak Supervision},
  author    = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and Mcleavey, Christine and Sutskever, Ilya},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning},
  pages     = {28492--28518},
  year      = {2023},
  editor    = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume    = {202},
  series    = {Proceedings of Machine Learning Research},
  month     = {23--29 Jul},
  publisher = {PMLR},
  pdf       = {https://proceedings.mlr.press/v202/radford23a/radford23a.pdf},
  url       = {https://proceedings.mlr.press/v202/radford23a.html}
}

@inproceedings{10096500,
  author    = {Zhang, Tuo and Feng, Tiantian and Alam, Samiul and Lee, Sunwoo and Zhang, Mi and Narayanan, Shrikanth S. and Avestimehr, Salman},
  booktitle = {ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {FedAudio: A Federated Learning Benchmark for Audio Tasks},
  year      = {2023},
  volume    = {},
  number    = {},
  pages     = {1-5},
  keywords  = {Training;Federated learning;Catalysts;Signal processing algorithms;Benchmark testing;Signal processing;Acoustics;federated learning;audio benchmarks},
  doi       = {10.1109/ICASSP49357.2023.10096500}
}


@article{zeng2024federated,
  title         = {Federated Recommendation via Hybrid Retrieval Augmented Generation},
  author        = {Huimin Zeng and Zhenrui Yue and Qian Jiang and Dong Wang},
  year          = {2024},
  eprint        = {2403.04256},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  url           = {https://arxiv.org/abs/2403.04256},
  journal       = {arXiv preprint arXiv:2403.04256},
  tags          = {application, Recommendation Systems},
  github        = {https://github.com/huiminzeng/GPT-FedRec}
}

@article{BOBADILLA2013109,
  title    = {Recommender systems survey},
  journal  = {Knowledge-Based Systems},
  volume   = {46},
  pages    = {109-132},
  year     = {2013},
  issn     = {0950-7051},
  doi      = {https://doi.org/10.1016/j.knosys.2013.03.012},
  url      = {https://www.sciencedirect.com/science/article/pii/S0950705113001044},
  author   = {J. Bobadilla and F. Ortega and A. Hernando and A. Gutierrez},
  keywords = {Recommender systems, Collaborative filtering, Similarity measures, Evaluation metrics, Prediction, Recommendation, Hybrid, Social, Internet of things, Cold-start}
}

@article{ammaduddin2019federated,
  title         = {Federated Collaborative Filtering for Privacy-Preserving Personalized Recommendation System},
  author        = {Muhammad Ammad-Ud-Din and Elena Ivannikova and Suleiman A. Khan and Were Oyomno and Qiang Fu and Kuan Eeik Tan and Adrian Flanagan},
  year          = {2019},
  eprint        = {1901.09888},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  url           = {https://arxiv.org/abs/1901.09888},
  journal       = {arXiv preprint arXiv:1901.09888}
}

@article{10.1145/3578361,
  author     = {Zhang, Honglei and Luo, Fangyuan and Wu, Jun and He, Xiangnan and Li, Yidong},
  title      = {LightFR: Lightweight Federated Recommendation with Privacy-preserving Matrix Factorization},
  year       = {2023},
  issue_date = {October 2023},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {41},
  number     = {4},
  issn       = {1046-8188},
  url        = {https://doi.org/10.1145/3578361},
  doi        = {10.1145/3578361},
  journal    = {ACM Trans. Inf. Syst.},
  month      = {mar},
  articleno  = {90},
  numpages   = {28},
  keywords   = {Federated recommender system, matrix factorization, privacy preservation, learning to hash}
}


@article{gao2023chatrec,
  title         = {Chat-REC: Towards Interactive and Explainable LLMs-Augmented Recommender System},
  author        = {Yunfan Gao and Tao Sheng and Youlin Xiang and Yun Xiong and Haofen Wang and Jiawei Zhang},
  year          = {2023},
  eprint        = {2303.14524},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  url           = {https://arxiv.org/abs/2303.14524},
  journal       = {arXiv preprint arXiv:2303.14524}
}

@article{wu2023survey,
  title         = {A Survey on Large Language Models for Recommendation},
  author        = {Likang Wu and Zhi Zheng and Zhaopeng Qiu and Hao Wang and Hongchao Gu and Tingjia Shen and Chuan Qin and Chen Zhu and Hengshu Zhu and Qi Liu and Hui Xiong and Enhong Chen},
  year          = {2023},
  eprint        = {2305.19860},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  url           = {https://arxiv.org/abs/2305.19860},
  journal       = {arXiv preprint arXiv:2305.19860}
}

@article{zhang2023recommendation,
  title         = {Recommendation as Instruction Following: A Large Language Model Empowered Recommendation Approach},
  author        = {Junjie Zhang and Ruobing Xie and Yupeng Hou and Wayne Xin Zhao and Leyu Lin and Ji-Rong Wen},
  year          = {2023},
  eprint        = {2305.07001},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  url           = {https://arxiv.org/abs/2305.07001},
  journal       = {arXiv preprint arXiv:2305.07001}
}

@inproceedings{10.1145/3485447.3511988,
  author    = {Wang, Haoyu and Zhao, Handong and Wang, Yaqing and Yu, Tong and Gu, Jiuxiang and Gao, Jing},
  title     = {FedKC: Federated Knowledge Composition for Multilingual Natural Language Understanding},
  year      = {2022},
  month     = {apr},
  isbn      = {9781450390965},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3485447.3511988},
  doi       = {10.1145/3485447.3511988},
  booktitle = {Proceedings of the ACM Web Conference 2022},
  pages     = {1839�1850},
  numpages  = {12},
  keywords  = {Federated learning, Multilingual natural language understanding},
  location  = {<conf-loc>, <city>Virtual Event, Lyon</city>, <country>France</country>, </conf-loc>},
  tags      = {Application, Multilingualism},
  series    = {WWW '22},
  venue     = {WWW}
}

@inproceedings{10.1145/3580305.3599825,
  author    = {Feng, Tiantian and Bose, Digbalay and Zhang, Tuo and Hebbar, Rajat and Ramakrishna, Anil and Gupta, Rahul and Zhang, Mi and Avestimehr, Salman and Narayanan, Shrikanth},
  title     = {FedMultimodal: A Benchmark for Multimodal Federated Learning},
  year      = {2023},
  isbn      = {9798400701030},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3580305.3599825},
  doi       = {10.1145/3580305.3599825},
  booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages     = {4035�4045},
  numpages  = {11},
  keywords  = {multimodal learning, multimodal benchmark, federated learning},
  location  = {<conf-loc>, <city>Long Beach</city>, <state>CA</state>, <country>USA</country>, </conf-loc>},
  series    = {KDD '23}
}

@article{Dai_Wei_Liu_Sun_Wang_Zheng_2024,
  title   = {Federated Modality-Specific Encoders and Multimodal Anchors for Personalized Brain Tumor Segmentation},
  volume  = {38},
  url     = {https://ojs.aaai.org/index.php/AAAI/article/view/27909},
  doi     = {10.1609/aaai.v38i2.27909},
  number  = {2},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  author  = {Dai, Qian and Wei, Dong and Liu, Hong and Sun, Jinghan and Wang, Liansheng and Zheng, Yefeng},
  year    = {2024},
  month   = {Mar.},
  pages   = {1445-1453}
}


@inproceedings{yu2023multimodal,
  title     = {Multimodal Federated Learning via Contrastive Representation Ensemble},
  author    = {Qiying Yu and Yang Liu and Yimu Wang and Ke Xu and Jingjing Liu},
  booktitle = {The Eleventh International Conference on Learning Representations },
  year      = {2023},
  url       = {https://openreview.net/forum?id=Hnk1WRMAYqg}
}

@article{liu2019roberta,
  title         = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  author        = {Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
  year          = {2019},
  eprint        = {1907.11692},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1907.11692},
  journal       = {arXiv preprint arXiv:1907.11692}
}

@inproceedings{bai2024federated,
  title         = {Federated Fine-tuning of Large Language Models under Heterogeneous Language Tasks and Client Resources},
  author        = {Jiamu Bai and Daoyuan Chen and Bingchen Qian and Liuyi Yao and Yaliang Li},
  year          = {2024},
  venue = {NeurIPS},
  github        = {https://github.com/alibaba/FederatedScope/tree/FlexLoRA},
  tags          = {efficiency, LoRA, reparameterization-based, heterogeneous resource},
  url           = {https://openreview.net/forum?id=gkOzoHBXUw},
}

@inproceedings{
anonymous2025enhancing,
title={Enhancing Federated Domain Adaptation with Multi-Domain Prototype-Based Federated Fine-Tuning},
author={Jingyuan Zhang and Yiyang Duan and Shuaicheng Niu and Yang Cao and Wei Yang Bryan Lim},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
month = {apr},
venue = {ICLR},
tags    = {efficiency, additive tuning, adapter tuning, adaptability, domain-centric adaptation, multi-domain adaptation},
url={https://openreview.net/forum?id=3wEGdrV5Cb}
}


@article{anil2023palm,
  title         = {PaLM 2 Technical Report},
  year          = {2023},
  author        = {Anil, Rohan and Dai, Andrew M and Firat, Orhan and Johnson, Melvin and Lepikhin, Dmitry and Passos, Alexandre and Shakeri, Siamak and Taropa, Emanuel and Bailey, Paige and Chen, Zhifeng and others},
  eprint        = {2305.10403},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2305.10403},
  journal       = {arXiv preprint arXiv:2305.10403}
}

@article{wu2020visual,
  title         = {Visual Transformers: Token-based Image Representation and Processing for Computer Vision},
  author        = {Bichen Wu and Chenfeng Xu and Xiaoliang Dai and Alvin Wan and Peizhao Zhang and Zhicheng Yan and Masayoshi Tomizuka and Joseph Gonzalez and Kurt Keutzer and Peter Vajda},
  year          = {2020},
  eprint        = {2006.03677},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2006.03677},
  journal       = {arXiv preprint arXiv:2006.03677}
}

@inproceedings{NEURIPS2021_50525975,
  author    = {Li, Junnan and Selvaraju, Ramprasaath and Gotmare, Akhilesh and Joty, Shafiq and Xiong, Caiming and Hoi, Steven Chu Hong},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
  pages     = {9694--9705},
  publisher = {Curran Associates, Inc.},
  title     = {Align before Fuse: Vision and Language Representation Learning with Momentum Distillation},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2021/file/505259756244493872b7709a8a01b536-Paper.pdf},
  volume    = {34},
  year      = {2021}
}

@article{sanh2020distilbert,
  title         = {DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author        = {Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
  year          = {2020},
  eprint        = {1910.01108},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1910.01108},
  journal       = {arXiv preprint arXiv:1910.01108}
}

@article{tang2020multilingual,
  title         = {Multilingual Translation with Extensible Multilingual Pretraining and Finetuning},
  author        = {Yuqing Tang and Chau Tran and Xian Li and Peng-Jen Chen and Naman Goyal and Vishrav Chaudhary and Jiatao Gu and Angela Fan},
  year          = {2020},
  eprint        = {2008.00401},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2008.00401},
  journal       = {arXiv preprint arXiv:2008.00401}
}

@article{radford2019rewon,
  title   = {Rewon child, david luan, dario amodei, and ilya sutskever. 2019},
  author  = {Radford, Alec and Wu, Jeffrey},
  journal = {Language models are unsupervised multitask learners. OpenAI blog},
  url     = {https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf},
  volume  = {1},
  number  = {8},
  pages   = {9},
  year    = {2019}
}

@article{pires2019multilingual,
  title         = {How multilingual is Multilingual BERT?},
  author        = {Telmo Pires and Eva Schlinger and Dan Garrette},
  year          = {2019},
  eprint        = {1906.01502},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1906.01502},
  journal       = {arXiv preprint arXiv:1906.01502}
}


@inproceedings{lester-etal-2021-power,
  title     = {The Power of Scale for Parameter-Efficient Prompt Tuning},
  author    = {Lester, Brian  and
               Al-Rfou, Rami  and
               Constant, Noah},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  month     = nov,
  year      = {2021},
  address   = {Online and Punta Cana, Dominican Republic},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.emnlp-main.243},
  doi       = {10.18653/v1/2021.emnlp-main.243},
  pages     = {3045--3059}
}

@inproceedings{weller-etal-2022-pretrained,
  title     = {Pretrained Models for Multilingual Federated Learning},
  author    = {Weller, Orion  and
               Marone, Marc  and
               Braverman, Vladimir  and
               Lawrie, Dawn  and
               Van Durme, Benjamin},
  booktitle = {Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  month     = jul,
  year      = {2022},
  address   = {Seattle, United States},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.naacl-main.101},
  doi       = {10.18653/v1/2022.naacl-main.101},
  github    = {https://github.com/orionw/Multilingual-Federated-Learning},
  venue     = {NAACL},
  tags      = {Application, Multilingualism},
  pages     = {1413--1421}
}


@inproceedings{guo-etal-2024-fedlfc,
  title     = {{F}ed{LFC}: Towards Efficient Federated Multilingual Modeling with {L}o{RA}-based Language Family Clustering},
  author    = {Guo, Zhihan  and
               Zhang, Yifei  and
               Zhang, Zhuo  and
               Xu, Zenglin  and
               King, Irwin},
  editor    = {Duh, Kevin  and
               Gomez, Helena  and
               Bethard, Steven},
  booktitle = {Findings of the Association for Computational Linguistics: NAACL 2024},
  month     = jun,
  year      = {2024},
  address   = {Mexico City, Mexico},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.findings-naacl.98},
  pages     = {1519--1528}
}



@inproceedings{devlin-etal-2019-bert,
  title     = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author    = {Devlin, Jacob  and
               Chang, Ming-Wei  and
               Lee, Kenton  and
               Toutanova, Kristina},
  booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  month     = jun,
  year      = {2019},
  address   = {Minneapolis, Minnesota},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/N19-1423},
  doi       = {10.18653/v1/N19-1423},
  pages     = {4171--4186}
}

@inproceedings{ben-zaken-etal-2022-bitfit,
  title     = {{B}it{F}it: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models},
  author    = {Ben Zaken, Elad  and
               Goldberg, Yoav  and
               Ravfogel, Shauli},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  month     = may,
  year      = {2022},
  address   = {Dublin, Ireland},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.acl-short.1},
  doi       = {10.18653/v1/2022.acl-short.1},
  pages     = {1--9}
}

@inproceedings{aghajanyan-etal-2021-intrinsic,
  title     = {Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning},
  author    = {Aghajanyan, Armen  and
               Gupta, Sonal  and
               Zettlemoyer, Luke},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  month     = aug,
  year      = {2021},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.acl-long.568},
  doi       = {10.18653/v1/2021.acl-long.568},
  pages     = {7319--7328}
}

@inproceedings{wu-dredze-2020-languages,
  title     = {Are All Languages Created Equal in Multilingual {BERT}?},
  author    = {Wu, Shijie  and
               Dredze, Mark},
  booktitle = {Proceedings of the 5th Workshop on Representation Learning for NLP},
  month     = jul,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.repl4nlp-1.16},
  doi       = {10.18653/v1/2020.repl4nlp-1.16},
  pages     = {120--130}
}

@inproceedings{conneau-etal-2020-unsupervised,
  title     = {Unsupervised Cross-lingual Representation Learning at Scale},
  author    = {Conneau, Alexis  and
               Khandelwal, Kartikay  and
               Goyal, Naman  and
               Chaudhary, Vishrav  and
               Wenzek, Guillaume  and
               Guzm{\'a}n, Francisco  and
               Grave, Edouard  and
               Ott, Myle  and
               Zettlemoyer, Luke  and
               Stoyanov, Veselin},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.acl-main.747},
  doi       = {10.18653/v1/2020.acl-main.747},
  pages     = {8440--8451}
}


@inproceedings{pmlr-v209-manoel23a,
  title     = {Federated Multilingual Models for Medical Transcript Analysis},
  author    = {Manoel, Andrea and Garcia, Mirian del Carmen Hipolito and Baumel, Tal and Su, Shize and Chen, Jialei and Sim, Robert and Miller, Dan and Karmon, Danny and Dimitriadis, Dimitrios},
  booktitle = {Proceedings of the Conference on Health, Inference, and Learning},
  pages     = {147--162},
  year      = {2023},
  editor    = {Mortazavi, Bobak J. and Sarker, Tasmie and Beam, Andrew and Ho, Joyce C.},
  volume    = {209},
  series    = {Proceedings of Machine Learning Research},
  month     = {jun},
  publisher = {PMLR},
  pdf       = {https://proceedings.mlr.press/v209/manoel23a/manoel23a.pdf},
  url       = {https://proceedings.mlr.press/v209/manoel23a.html},
  tags      = {Application, Multilingualism, Domain, Domain Specific, Healthcare},
  venue     = {CHIL}
}

@article{yang2024dualpersonalizing,
  title         = {Dual-Personalizing Adapter for Federated Foundation Models},
  author        = {Yiyuan Yang and Guodong Long and Tao Shen and Jing Jiang and Michael Blumenstein},
  year          = {2024},
  eprint        = {2403.19211},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2403.19211},
  tags          = {efficiency, reparameterization-based, personalization},
  journal       = {arXiv preprint arXiv:2403.19211}
}

@article{10.1162/tacl_a_00065,
  author  = {Johnson, Melvin and Schuster, Mike and Le, Quoc
             V. and Krikun, Maxim and Wu, Yonghui and Chen, Zhifeng and Thorat, Nikhil and Vi�gas, Fernanda and Wattenberg, Martin and Corrado, Greg and Hughes, Macduff and Dean, Jeffrey},
  title   = {{Google�s Multilingual Neural Machine Translation System: Enabling
             Zero-Shot Translation}},
  journal = {Transactions of the Association for Computational Linguistics},
  volume  = {5},
  pages   = {339-351},
  year    = {2017},
  month   = {10},
  issn    = {2307-387X},
  doi     = {10.1162/tacl_a_00065},
  url     = {https://doi.org/10.1162/tacl\_a\_00065},
  eprint  = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00065/1567476/tacl\_a\_00065.pdf}
}

@article{bai2024diprompt,
  title   = {DiPrompT: Disentangled Prompt Tuning for Multiple Latent Domain Generalization in Federated Learning},
  author  = {Sikai Bai and Jie Zhang and Shuaicheng Li and Song Guo and Jingcai Guo and Jun Hou and Tao Han and Xiaocheng Lu},
  year    = {2024},
  venue   = {CVPR},
  month   = {jun},
  url     = {https://arxiv.org/abs/2403.08506},
  journal = {arXiv preprint arXiv:2403.08506},
  tags    = {efficiency, additive tuning, prompt tuning, textual-visual prompt tuning, adaptability, domain-centric adaptation, multi-domain adaptation}
}




@article{liu2024fedfms,
  title         = {FedFMS: Exploring Federated Foundation Models for Medical Image Segmentation},
  author        = {Yuxi Liu and Guibo Luo and Yuesheng Zhu},
  year          = {2024},
  eprint        = {2403.05408},
  archiveprefix = {arXiv},
  venue         = {MICCAI},
  primaryclass  = {eess.IV},
  github        = {https://github.com/LIU-YUXI/FedFMS},
  url           = {https://arxiv.org/abs/2403.05408},
  journal       = {arXiv preprint arXiv:2403.05408},
  tags          = {application, domain specific, healthcare}
}

@article{wei2024dual,
  title         = {Dual Prompt Tuning for Domain-Aware Federated Learning},
  author        = {Guoyizhe Wei and Feng Wang and Anshul Shah and Rama Chellappa},
  year          = {2024},
  eprint        = {2310.03103},
  archiveprefix = {arXiv},
  tags          = {efficiency, additive tuning, prompt tuning, textual-visual prompt tuning, domain-awareness, adaptability, domain-centric adaptation},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2310.03103},
  journal       = {arXiv preprint arXiv:2310.03103}
}

@article{deng2023unlocking,
  title   = {Unlocking the Potential of Prompt-Tuning in Bridging Generalized and Personalized Federated Learning},
  author  = {Deng, Wenlong and Thrampoulidis, Christos and Li, Xiaoxiao},
  journal = {CVPR},
  pages   = {},
  venue   = {CVPR},
  month   = {jun},
  github  = {https://github.com/ubc-tea/SGPT},
  tags    = {efficiency, additive tuning,  prompt tuning, visual prompt tuning},
  url     = {https://arxiv.org/abs/2310.18285},
  year    = {2024}
}

@article{li2024global,
  title   = {Global and Local Prompts Cooperation via Optimal Transport for Federated Learning},
  author  = {Li, Hongxia and Huang, Wei and Wang, Jingya and Shi, Ye},
  journal = {CVPR},
  venue   = {CVPR},
  url     = {https://arxiv.org/abs/2403.00041},
  github  = {https://github.com/HongxiaLee/FedOTP},
  tags    = {efficiency, additive tuning, prompt tuning, textual-visual prompt tuning},
  month   = {jun},
  year    = {2024}
}

@inproceedings{dai2024enhancing,
  title     = {Enhancing One-Shot Federated Learning Through Data and Ensemble Co-Boosting},
  author    = {Rong Dai and Yonggang Zhang and Ang Li and Tongliang Liu and Xun Yang and Bo Han},
  booktitle = {The Twelfth International Conference on Learning Representations},
  year      = {2024},
  month     = {may},
  venue     = {ICLR},
  github    = {https://github.com/rong-dai/Co-Boosting},
  url       = {https://openreview.net/forum?id=tm8s3696Ox},
  tags      = {adaptation, data level}
}

@article{beitollahi2024parametric,
  title         = {Parametric Feature Transfer: One-shot Federated Learning with Foundation Models},
  author        = {Mahdi Beitollahi and Alex Bie and Sobhan Hemati and Leo Maxime Brunswic and Xu Li and Xi Chen and Guojun Zhang},
  year          = {2024},
  eprint        = {2402.01862},
  archiveprefix = {arXiv},
  tags          = {adaptation, data level},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2402.01862},
  journal       = {arXiv preprint arXiv:2402.01862}
}

@article{Ma_Yin_Tan_Chen_Huang_Wang_Xue_Ban_2024,
  title   = {FedST: Federated Style Transfer Learning for Non-IID Image Segmentation},
  volume  = {38},
  url     = {https://ojs.aaai.org/index.php/AAAI/article/view/28199},
  doi     = {10.1609/aaai.v38i5.28199},
  number  = {5},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  author  = {Ma, Boyuan and Yin, Xiang and Tan, Jing and Chen, Yongfeng and Huang, Haiyou and Wang, Hao and Xue, Weihua and Ban, Xiaojuan},
  year    = {2024},
  venue   = {AAAI},
  month   = {mar},
  pages   = {4053-4061},
  tags    = {adaptation, data level},
  github  = {https://github.com/YoferChen/FedST}
}

@article{zhang2024fedpit,
  title         = {FedPIT: Towards Privacy-preserving and Few-shot Federated Instruction Tuning},
  author        = {Zhuo Zhang and Jingyuan Zhang and Jintao Huang and Lizhen Qu and Hongzhi Zhang and Zenglin Xu},
  year          = {2024},
  eprint        = {2403.06131},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR},
  tags          = {adaptation, data level, LoRA, reparameterization-based},
  url           = {https://arxiv.org/abs/2403.06131},
  journal       = {arXiv preprint arXiv:2403.06131}
}

@article{Yang_Su_Li_Xue_2024,
  title  = {Exploring One-Shot Semi-supervised Federated Learning with Pre-trained Diffusion Models},
  volume = {38},
  url    = {https://ojs.aaai.org/index.php/AAAI/article/view/29568},
  doi    = {10.1609/aaai.v38i15.29568},
  author = {Yang, Mingzhao and Su, Shangchao and Li, Bin and Xue, Xiangyang},
  year   = {2024},
  venue  = {AAAI},
  tags   = {adaptation, data level},
  month  = {mar},
  github = {https://github.com/MingzhaoYang/FedDISC},
  pages  = {16325-16333}
}


@inproceedings{ping2024fltac,
  title     = {{FL}-{TAC}: Enhanced Fine-Tuning in Federated Learning via Low-Rank, Task-Specific Adapter Clustering},
  author    = {Siqi Ping and Yuzhu Mao and Yang Liu and Xiao-Ping Zhang and Wenbo Ding},
  booktitle = {ICLR 2024 Workshop on Large Language Model (LLM) Agents},
  year      = {2024},
  month     = {may},
  venue     = {LLMAgents\@ICLR},
  tags      = {efficiency, LoRA, reparameterization-based},
  url       = {https://openreview.net/forum?id=JDmAymuFFQ}
}

@article{nguyen2024flora,
  title         = {FLoRA: Enhancing Vision-Language Models with Parameter-Efficient Federated Learning},
  author        = {Duy Phuong Nguyen and J. Pablo Munoz and Ali Jannesari},
  year          = {2024},
  eprint        = {2404.15182},
  archiveprefix = {arXiv},
  tags          = {efficiency, LoRA, reparameterization-based},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2404.15182},
  journal       = {arXiv preprint arXiv:2404.15182}
}

@article{singh2019detailed,
  title         = {Detailed comparison of communication efficiency of split learning and federated learning},
  author        = {Abhishek Singh and Praneeth Vepakomma and Otkrist Gupta and Ramesh Raskar},
  year          = {2019},
  eprint        = {1909.09145},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/1909.09145},
  journal       = {arXiv preprint arXiv:1909.09145}
}

@inproceedings{10.24963/ijcai.2023/519,
  author    = {Zheng, Fei and Chen, Chaochao and Lyu, Lingjuan and Yao, Binhui},
  title     = {Reducing communication for split learning by randomized top-k sparsification},
  year      = {2023},
  isbn      = {978-1-956792-03-4},
  url       = {https://doi.org/10.24963/ijcai.2023/519},
  doi       = {10.24963/ijcai.2023/519},
  booktitle = {Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence},
  articleno = {519},
  numpages  = {9},
  location  = {<conf-loc>, <city>Macao</city>, <country>P.R.China</country>, </conf-loc>},
  series    = {IJCAI '23},
  venue     = {IJCAI}
}

@article{deng2023mutual,
  title         = {Mutual Enhancement of Large and Small Language Models with Cross-Silo Knowledge Transfer},
  author        = {Yongheng Deng and Ziqing Qiao and Ju Ren and Yang Liu and Yaoxue Zhang},
  year          = {2023},
  eprint        = {2312.05842},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  tags          = {adaptation, data level},
  url           = {https://arxiv.org/abs/2312.05842},
  journal       = {arXiv preprint arXiv:2312.05842}
}




@article{liu2024foundation,
  title     = {Foundation models matter: federated learning for multi-center tuberculosis diagnosis via adaptive regularization and model-contrastive learning},
  author    = {Liu, Chang and Luo, Yong and Xu, Yongchao and Du, Bo},
  journal   = {World Wide Web},
  volume    = {27},
  number    = {3},
  month     = {may},
  pages     = {1--17},
  venue     = {WWW},
  url       = {https://link.springer.com/article/10.1007/s11280-024-01266-3},
  tags      = {application, healthcare, domain specific},
  year      = {2024},
  publisher = {Springer}
}

@article{spall1992multivariate,
  author  = {Spall, J.C.},
  journal = {IEEE Transactions on Automatic Control},
  title   = {Multivariate stochastic approximation using a simultaneous perturbation gradient approximation},
  year    = {1992},
  volume  = {37},
  number  = {3},
  pages   = {332-341},
  url     = {https://ieeexplore.ieee.org/document/119632}
}

 @article{9186148,
  author   = {Liu, Sijia and Chen, Pin-Yu and Kailkhura, Bhavya and Zhang, Gaoyuan and Hero III, Alfred O. and Varshney, Pramod K.},
  journal  = {IEEE Signal Processing Magazine},
  title    = {A Primer on Zeroth-Order Optimization in Signal Processing and Machine Learning: Principals, Recent Advances, and Applications},
  year     = {2020},
  volume   = {37},
  number   = {5},
  url      = {https://ieeexplore.ieee.org/abstract/document/9186148},
  pages    = {43-54},
  keywords = {Optimization;Estimation;Signal processing algorithms;Linear programming;Signal processing;Convergence;Approximation error},
  doi      = {10.1109/MSP.2020.3003837}
}

@article{duchi2015optimal,
  title     = {Optimal rates for zero-order convex optimization: The power of two function evaluations},
  author    = {Duchi, John C and Jordan, Michael I and Wainwright, Martin J and Wibisono, Andre},
  journal   = {IEEE Transactions on Information Theory},
  volume    = {61},
  number    = {5},
  pages     = {2788--2806},
  year      = {2015},
  publisher = {IEEE}
}

@article{shi2024heterogeneous,
  title         = {Heterogeneous Federated Learning with Splited Language Model},
  author        = {Yifan Shi and Yuhui Zhang and Ziyue Huang and Xiaofeng Yang and Li Shen and Wei Chen and Xueqian Wang},
  year          = {2024},
  eprint        = {2403.16050},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2403.16050},
  journal       = {arXiv preprint arXiv:2403.16050},
  tags          = {efficiency, split learning, heterogeneous resource}
}

@article{10041745,
  author   = {Wang, Zhousheng and Yang, Geng and Dai, Hua and Rong, Chunming},
  journal  = {IEEE Transactions on Information Forensics and Security},
  title    = {Privacy-Preserving Split Learning for Large-Scaled Vision Pre-Training},
  year     = {2023},
  volume   = {18},
  month    = {feb},
  venue    = {TIFS},
  url      = {https://ieeexplore.ieee.org/document/10041745},
  pages    = {1539-1553},
  tags     = {efficiency, split learning, heterogeneous resource},
  keywords = {Computational modeling;Training;Federated learning;Privacy;Data models;Transformers;Task analysis;Split learning;self pre-training;differential privacy;masked autoencoder},
  doi      = {10.1109/TIFS.2023.3243490}
}

@misc{zheng2024safelylearningprivatedata,
  title         = {Safely Learning with Private Data: A Federated Learning Framework for Large Language Model},
  author        = {JiaYing Zheng and HaiNan Zhang and LingXiang Wang and WangJie Qiu and HongWei Zheng and ZhiMing Zheng},
  year          = {2024},
  eprint        = {2406.14898},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR},
  tags          = {efficiency, split learning, heterogeneous resource},
  url           = {https://arxiv.org/abs/2406.14898}
}


@inproceedings{9892845,
  author    = {Lit, Zhengyang and Sit, Shijing and Wang, Jianzong and Xiao, Jing},
  booktitle = {2022 International Joint Conference on Neural Networks (IJCNN)},
  title     = {Federated Split BERT for Heterogeneous Text Classification},
  year      = {2022},
  volume    = {},
  number    = {},
  pages     = {1-8},
  venue     = {IJCNN},
  doi       = {10.1109/IJCNN55064.2022.9892845},
  url       = {https://ieeexplore.ieee.org/document/9892845},
  tags      = {efficiency, split learning, heterogeneous resource}
}

@inproceedings{sun-etal-2022-bbtv2,
  title     = {{BBT}v2: Towards a Gradient-Free Future with Large Language Models},
  author    = {Sun, Tianxiang  and
               He, Zhengfu  and
               Qian, Hong  and
               Zhou, Yunhua  and
               Huang, Xuanjing  and
               Qiu, Xipeng},
  editor    = {Goldberg, Yoav  and
               Kozareva, Zornitsa  and
               Zhang, Yue},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  month     = dec,
  year      = {2022},
  address   = {Abu Dhabi, United Arab Emirates},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.emnlp-main.259},
  doi       = {10.18653/v1/2022.emnlp-main.259},
  pages     = {3916--3930}
}

@inproceedings{NaseriHC22,
  author    = {Mohammad Naseri and
               Jamie Hayes and
               Emiliano De Cristofaro},
  title     = {Local and Central Differential Privacy for Robustness and Privacy
               in Federated Learning},
  booktitle = {29th Annual Network and Distributed System Security Symposium, {NDSS}
               2022, San Diego, California, USA, April 24-28, 2022},
  publisher = {The Internet Society},
  year      = {2022},
  url       = {https://www.ndss-symposium.org/ndss-paper/auto-draft-204/},
  timestamp = {Thu, 15 Jun 2023 16:53:21 +0200},
  biburl    = {https://dblp.org/rec/conf/ndss/NaseriHC22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{10.1145/3589335.3651933,
  author    = {Guo, Zhihan and Zhang, Yifei and Zhang, Zhuo and Xu, Zenglin and King, Irwin},
  title     = {FedHLT: Efficient Federated Low-Rank Adaption with Hierarchical Language Tree for Multilingual Modeling},
  year      = {2024},
  isbn      = {9798400701726},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3589335.3651933},
  doi       = {10.1145/3589335.3651933},
  booktitle = {Companion Proceedings of the ACM on Web Conference 2024},
  pages     = {1558�1567},
  numpages  = {10},
  keywords  = {federated multilingual modeling, hierarchical federated learning, low-rank adaption},
  location  = {<conf-loc>, <city>Singapore</city>, <country>Singapore</country>, </conf-loc>},
  series    = {WWW '24},
  venue     = {WWW},
  month     = {may},
  tags      = {efficiency, LoRA, reparameterization-based, application, multilingualism}
}

@inproceedings{10.1145/3589334.3645337,
  author    = {Guo, Lei and Lu, Ziang and Yu, Junliang and Nguyen, Quoc Viet Hung and Yin, Hongzhi},
  title     = {Prompt-enhanced Federated Content Representation Learning for Cross-domain Recommendation},
  year      = {2024},
  isbn      = {9798400701719},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3589334.3645337},
  doi       = {10.1145/3589334.3645337},
  booktitle = {Proceedings of the ACM on Web Conference 2024},
  pages     = {3139�3149},
  numpages  = {11},
  venue     = {WWW},
  month     = {may},
  github    = {https://github.com/Ckano/PFCR},
  tags      = {application, Recommendation Systems, adaptability, domain-centric adaptation},
  keywords  = {content representation, cross-domain recommendation, federated learning},
  location  = {<conf-loc>, <city>Singapore</city>, <country>Singapore</country>, </conf-loc>},
  series    = {WWW '24}
}

@inproceedings{azam2023federated,
  title     = {Federated Learning for Speech Recognition: Revisiting Current Trends Towards Large-Scale {ASR}},
  author    = {Sheikh Shams Azam and Martin Pelikan and Vitaly Feldman and Kunal Talwar and Jan Silovsky and Tatiana Likhomanenko},
  booktitle = {International Workshop on Federated Learning in the Age of Foundation Models in Conjunction with NeurIPS 2023},
  year      = {2023},
  venue     = {FL\@FM-NeurIPS},
  month     = {dec},
  tags      = {application, speech},
  url       = {https://openreview.net/forum?id=ozN92d7CHX}
}

@article{10.1145/3571732,
  author     = {Madan, Chetan and Diddee, Harshita and Kumar, Deepika and Mittal, Mamta},
  title      = {CodeFed: Federated Speech Recognition for Low-Resource Code-Switching Detection},
  year       = {2024},
  issue_date = {January 2024},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {23},
  number     = {1},
  issn       = {2375-4699},
  url        = {https://doi.org/10.1145/3571732},
  doi        = {10.1145/3571732},
  journal    = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
  month      = {jan},
  articleno  = {2},
  numpages   = {14},
  keywords   = {mobile computing, federated learning, speech processing, low resource Indian languages, Code-switching}
}

@inproceedings{10195024,
  author    = {Peng, Danni and Wang, Yuan and Fu, Huazhu and Wei, Qingsong and Liu, Yong and Goh, Rick Siow Mong},
  booktitle = {2023 IEEE Conference on Artificial Intelligence (CAI)},
  title     = {Learning Task-Specific Initialization for Effective Federated Continual Fine-Tuning of Foundation Model Adapters},
  year      = {2024},
  venue     = {IEEE CAI},
  month     = {jun},
  url       = {https://danni9594.github.io/publications/CAI24_FedCAF.pdf},
  tags      = {adaptability, domain-centric adaptation, efficiency, additive tuning, adapter tuning},
  doi       = {10.1109/CAI54212.2023.00013}
}

@inproceedings{zhang-etal-2024-revisiting-data,
  title     = {Revisiting Data Reconstruction Attacks on Real-world Dataset for Federated Natural Language Understanding},
  author    = {Zhang, Zhuo  and
               Huang, Jintao  and
               Hu, Xiangjing  and
               Zhang, Jingyuan  and
               Zhang, Yating  and
               Wang, Hui  and
               Yu, Yue  and
               Wang, Qifan  and
               Qu, Lizhen  and
               Xu, Zenglin},
  editor    = {Calzolari, Nicoletta  and
               Kan, Min-Yen  and
               Hoste, Veronique  and
               Lenci, Alessandro  and
               Sakti, Sakriani  and
               Xue, Nianwen},
  booktitle = {Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},
  month     = may,
  year      = {2024},
  address   = {Torino, Italia},
  publisher = {ELRA and ICCL},
  url       = {https://aclanthology.org/2024.lrec-main.1227},
  pages     = {14080--14091}
}

@inproceedings{10.1007/978-981-97-2259-4_13,
  author    = {Li, Xi
               and Wu, Chen
               and Wang, Jiaqi},
  editor    = {Yang, De-Nian
               and Xie, Xing
               and Tseng, Vincent S.
               and Pei, Jian
               and Huang, Jen-Wei
               and Lin, Jerry Chun-Wei},
  title     = {Unveiling Backdoor Risks Brought by Foundation Models in Heterogeneous Federated Learning},
  booktitle = {Advances in Knowledge Discovery and Data Mining},
  year      = {2024},
  month     = {apr},
  url       = {https://link.springer.com/chapter/10.1007/978-981-97-2259-4_13},
  venue     = {PAKDD},
  publisher = {Springer Nature Singapore},
  address   = {Singapore},
  pages     = {168--181},
  tags      = {trustworthiness, security, attack robustness, poisoning attack},
  github    = {https://github.com/lixi1994/backdoor_FM_hete_FL},
  isbn      = {978-981-97-2259-4}
}

@misc{bi2024securingfederatedlearningnovel,
  title         = {Securing Federated Learning Against Novel and Classic Backdoor Threats During Foundation Model Integration},
  author        = {Xiaohuan Bi and Xi Li},
  year          = {2024},
  eprint        = {2410.17573},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2410.17573},
  tags          = {trustworthiness, security, attack robustness, poisoning attack}
}

@inproceedings{li2023backdoor,
  title     = {Backdoor Threats from Compromised Foundation Models to Federated Learning},
  author    = {Xi Li and Songhe Wang and Chen Wu and Hao Zhou and Jiaqi Wang},
  booktitle = {International Workshop on Federated Learning in the Age of Foundation Models in Conjunction with NeurIPS 2023},
  year      = {2023},
  venue     = {FL\@FM-NeurIPS},
  month     = {oct},
  tags      = {trustworthiness, security, attack robustness, poisoning attack},
  url       = {https://openreview.net/forum?id=BrcHuO2BVc}
}


@article{9945997,
  author   = {Lyu, Lingjuan and Yu, Han and Ma, Xingjun and Chen, Chen and Sun, Lichao and Zhao, Jun and Yang, Qiang and Yu, Philip S.},
  journal  = {IEEE Transactions on Neural Networks and Learning Systems},
  title    = {Privacy and Robustness in Federated Learning: Attacks and Defenses},
  year     = {2022},
  volume   = {},
  number   = {},
  pages    = {1-21},
  keywords = {Training;Data models;Robustness;Privacy;Servers;Computational modeling;Predictive models;Attacks;defenses;federated learning (FL);privacy;robustness},
  doi      = {10.1109/TNNLS.2022.3216981}
}

@article{rodriguez2023survey,
  title     = {Survey on federated learning threats: Concepts, taxonomy on attacks and defences, experimental study and challenges},
  author    = {Rodr{\'\i}guez-Barroso, Nuria and Jim{\'e}nez-L{\'o}pez, Daniel and Luz{\'o}n, M Victoria and Herrera, Francisco and Mart{\'\i}nez-C{\'a}mara, Eugenio},
  journal   = {Information Fusion},
  volume    = {90},
  pages     = {148--173},
  year      = {2023},
  url       = {https://www.sciencedirect.com/science/article/abs/pii/S1566253522001439},
  publisher = {Elsevier}
}

@article{jere2020taxonomy,
  title     = {A taxonomy of attacks on federated learning},
  author    = {Jere, Malhar S and Farnan, Tyler and Koushanfar, Farinaz},
  journal   = {IEEE Security \& Privacy},
  volume    = {19},
  number    = {2},
  year      = {2020},
  publisher = {IEEE}
}

@inproceedings{xie2019dba,
  title     = {DBA: Distributed Backdoor Attacks against Federated Learning},
  author    = {Chulin Xie and Keli Huang and Pin-Yu Chen and Bo Li},
  booktitle = {International Conference on Learning Representations},
  url       = {https://openreview.net/forum?id=rkgyS0VFvr},
  year      = {2020}
}


@inproceedings{fang2020local,
  title     = {Local model poisoning attacks to byzantine-robust federated learning},
  author    = {Fang, Minghong and Cao, Xiaoyu and Jia, Jinyuan and Gong, Neil},
  booktitle = {29th USENIX Security Symposium (USENIX Security 20)},
  pages     = {1605--1622},
  url       = {https://www.usenix.org/system/files/sec20summer_fang_prepub.pdf},
  year      = {2020}
}

@inproceedings{bagdasaryan2020backdoor,
  title        = {How to backdoor federated learning},
  author       = {Bagdasaryan, Eugene and Veit, Andreas and Hua, Yiqing and Estrin, Deborah and Shmatikov, Vitaly},
  booktitle    = {International Conference on Artificial Intelligence and Statistics},
  pages        = {2938--2948},
  url          = {https://proceedings.mlr.press/v108/bagdasaryan20a.html},
  year         = {2020},
  organization = {PMLR}
}


@inproceedings{li2024blades,
  author    = {Li, Shenghui and Ngai, Edith C.-H. and Ye, Fanghua and Ju, Li and Zhang, Tianru and Voigt, Thiemo},
  booktitle = {2024 IEEE/ACM Ninth International Conference on Internet-of-Things Design and Implementation (IoTDI)},
  title     = {Blades: A Unified Benchmark Suite for Byzantine Attacks and Defenses in Federated Learning},
  year      = {2024},
  venue     = {IoTDI},
  url       = {https://ieeexplore.ieee.org/document/10562176},
  pages     = {158-169},
  doi       = {10.1109/IoTDI61053.2024.00018}
}


@inproceedings{Shen_2021,
  series     = {CCS �21},
  title      = {Backdoor Pre-trained Models Can Transfer to All},
  url        = {http://dx.doi.org/10.1145/3460120.3485370},
  doi        = {10.1145/3460120.3485370},
  booktitle  = {Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security},
  publisher  = {ACM},
  author     = {Shen, Lujia and Ji, Shouling and Zhang, Xuhong and Li, Jinfeng and Chen, Jing and Shi, Jie and Fang, Chengfang and Yin, Jianwei and Wang, Ting},
  year       = {2021},
  month      = nov,
  collection = {CCS �21}
}

@inproceedings{blanchard2017machine,
  title     = {Machine learning with adversaries: Byzantine tolerant gradient descent},
  author    = {Blanchard, Peva and El Mhamdi, El Mahdi and Guerraoui, Rachid and Stainer, Julien},
  booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
  year      = {2017}
}

@article{chen2017distributed,
  title     = {Distributed statistical machine learning in adversarial settings: Byzantine gradient descent},
  author    = {Chen, Yudong and Su, Lili and Xu, Jiaming},
  journal   = {Proceedings of the ACM on Measurement and Analysis of Computing Systems},
  year      = {2017},
  publisher = {ACM New York, NY, USA}
}


@article{li2021byzantine,
  author  = {Li, Shenghui and Ngai, Edith and Voigt, Thiemo},
  journal = {IEEE Transactions on Industrial Informatics},
  title   = {Byzantine-Robust Aggregation in Federated Learning Empowered Industrial IoT},
  year    = {2023},
  volume  = {19},
  number  = {2},
  pages   = {1165-1175},
  doi     = {10.1109/TII.2021.3128164}
}


@inproceedings{yin2018byzantine,
  title        = {Byzantine-robust distributed learning: Towards optimal statistical rates},
  author       = {Yin, Dong and Chen, Yudong and Kannan, Ramchandran and Bartlett, Peter},
  booktitle    = {International Conference on Machine Learning},
  year         = {2018},
  organization = {PMLR}
}

@inproceedings{gorbunov2023variance,
  title     = {Variance Reduction is an Antidote to Byzantines: Better Rates, Weaker Assumptions and Communication Compression as a Cherry on the Top},
  author    = {Eduard Gorbunov and Samuel Horv{\'a}th and Peter Richt{\'a}rik and Gauthier Gidel},
  booktitle = {International Conference on Learning Representations},
  year      = {2023}
}

@article{9153949,
  author  = {Wu, Zhaoxian and Ling, Qing and Chen, Tianyi and Giannakis, Georgios B.},
  journal = {IEEE Transactions on Signal Processing},
  title   = {Federated Variance-Reduced Stochastic Gradient Descent With Robustness to Byzantine Attacks},
  year    = {2020},
  volume  = {68},
  number  = {},
  pages   = {4583-4596},
  doi     = {10.1109/TSP.2020.3012952}
}

@inproceedings{cao2021fltrust,
  title     = {FLTrust: Byzantine-robust Federated Learning via Trust Bootstrapping},
  author    = {Cao, Xiaoyu and Fang, Minghong and Liu, Jia and Gong, Neil Zhenqiang},
  booktitle = {ISOC Network and Distributed System Security Symposium (NDSS)},
  year      = {2021}
}

@article{9887909,
  author  = {Xu, Chang and Jia, Yu and Zhu, Liehuang and Zhang, Chuan and Jin, Guoxie and Sharif, Kashif},
  journal = {IEEE Transactions on Parallel and Distributed Systems},
  title   = {TDFL: Truth Discovery Based Byzantine Robust Federated Learning},
  year    = {2022},
  volume  = {33},
  number  = {12},
  doi     = {10.1109/TPDS.2022.3205714}
}

@inproceedings{sageflow,
  author    = {Park, Jungwuk and Han, Dong-Jun and Choi, Minseok and Moon, Jaekyun},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
  pages     = {840--851},
  publisher = {Curran Associates, Inc.},
  title     = {Sageflow: Robust Federated Learning against Both Stragglers and Adversaries},
  volume    = {34},
  year      = {2021}
}


@inproceedings{zhu-etal-2020-empirical,
  title     = {Empirical Studies of Institutional Federated Learning For Natural Language Processing},
  author    = {Zhu, Xinghua  and Wang, Jianzong  and Hong, Zhenhou  and Xiao, Jing},
  editor    = {Cohn, Trevor  and He, Yulan  and Liu, Yang},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2020},
  month     = nov,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.findings-emnlp.55},
  doi       = {10.18653/v1/2020.findings-emnlp.55},
  pages     = {625--634}
}


@article{10558823,
  author   = {Chen, Zihan and Yang, Howard H. and Tay, Y. C. and Chong, Kai Fong Ernest and Quek, Tony Q. S.},
  journal  = {IEEE Wireless Communications},
  title    = {The Role of Federated Learning in a Wireless World with Foundation Models},
  year     = {2024},
  volume   = {31},
  number   = {3},
  venue    = {IEEE WC},
  pages    = {42-49},
  tags     = {resources, surveys},
  url      = {https://ieeexplore.ieee.org/abstract/document/10558823},
  keywords = {Training;Intelligent networks;Frequency modulation;Federated learning;Generative AI;Wireless networks;Boosting},
  doi      = {10.1109/MWC.005.2300481}
}


@misc{li2024synergizingfoundationmodelsfederated,
      title={Synergizing Foundation Models and Federated Learning: A Survey},
      author={Shenghui Li and Fanghua Ye and Meng Fang and Jiaxu Zhao and Yun-Hin Chan and Edith C. -H. Ngai and Thiemo Voigt},
      year={2024},
      eprint={2406.12844},
      archivePrefix={arXiv},
  tags     = {resources, surveys},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.12844},
}


@article{10759678,
  author   = {Cheng, Yujun and Zhang, Weiting and Zhang, Zhewei and Zhang, Chuan and Wang, Shengjin and Mao, Shiwen},
  journal  = {IEEE Communications Surveys & Tutorials},
  title    = {Towards Federated Large Language Models: Motivations, Methods, and Future Directions},
  year     = {2024},
  month    = {oct},
  volume   = {},
  number   = {},
  tags     = {resources, surveys},
  url      = {https://ieeexplore.ieee.org/abstract/document/10759678},
  pages    = {1-1},
  venue    = {IEEE COMST},
  keywords = {Privacy;Surveys;Data models;Computational modeling;Training;Artificial intelligence;Security;Robustness;Reviews;Federated learning;Federated Learning;Large Language Model;Foundation model;Privacy},
  doi      = {10.1109/COMST.2024.3503680}
}

@article{ren2024advances,
  title         = {Advances and Open Challenges in Federated Learning with Foundation Models},
  author        = {Chao Ren and Han Yu and Hongyi Peng and Xiaoli Tang and Anran Li and Yulan Gao and Alysa Ziying Tan and Bo Zhao and Xiaoxiao Li and Zengxiang Li and Qiang Yang},
  year          = {2025},
  month = {jan},
  eprint        = {2404.15381},
  venue    = {IEEE COMST},
  tags          = {resources, surveys},
  url           = {https://arxiv.org/abs/2404.15381},
  journal       = {arXiv preprint arXiv:2404.15381}
}


@misc{yao2024federatedlargelanguagemodels,
      title={Federated Large Language Models: Current Progress and Future Directions},
      author={Yuhang Yao and Jianyi Zhang and Junda Wu and Chengkai Huang and Yu Xia and Tong Yu and Ruiyi Zhang and Sungchul Kim and Ryan Rossi and Ang Li and Lina Yao and Julian McAuley and Yiran Chen and Carlee Joe-Wong},
      year={2024},
      eprint={2409.15723},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
        tags          = {resources, surveys},
      url={https://arxiv.org/abs/2409.15723},
}


@inproceedings{254465,
  author    = {Chengliang Zhang and Suyi Li and Junzhe Xia and Wei Wang and Feng Yan and Yang Liu},
  title     = {{BatchCrypt}: Efficient Homomorphic Encryption for {Cross-Silo} Federated Learning},
  booktitle = {2020 USENIX Annual Technical Conference (USENIX ATC 20)},
  year      = {2020},
  isbn      = {978-1-939133-14-4},
  pages     = {493--506},
  url       = {https://www.usenix.org/conference/atc20/presentation/zhang-chengliang},
  publisher = {USENIX Association},
  month     = jul
}

@inproceedings{mugunthan2019smpai,
  title     = {SMPAI: Secure Multi-Party Computation for Federated Learning},
  author    = {Vaikkunth Mugunthan and David Byrd and Tucker Hybinette Balch and J. P. Morgan and AI Research},
  year      = {2019},
  volume    = {21},
  booktitle = {Proceedings of the NeurIPS 2019 Workshop on Robust AI in Financial Services},
  url       = {https://api.semanticscholar.org/CorpusID:220598116}
}

@inproceedings{NEURIPS2023_a6278101,
  author    = {Malladi, Sadhika and Gao, Tianyu and Nichani, Eshaan and Damian, Alex and Lee, Jason D and Chen, Danqi and Arora, Sanjeev},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
  pages     = {53038--53075},
  publisher = {Curran Associates, Inc.},
  title     = {Fine-Tuning Language Models with Just Forward Passes},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2023/file/a627810151be4d13f907ac898ff7e948-Paper-Conference.pdf},
  volume    = {36},
  year      = {2023}
}

@article{jeblick2024chatgpt,
  title     = {ChatGPT makes medicine easy to swallow: an exploratory case study on simplified radiology reports},
  author    = {Jeblick, Katharina and Schachtner, Balthasar and Dexl, Jakob and Mittermeier, Andreas and St{\"u}ber, Anna Theresa and Topalis, Johanna and Weber, Tobias and Wesp, Philipp and Sabel, Bastian Oliver and Ricke, Jens and others},
  journal   = {European radiology},
  volume    = {34},
  number    = {5},
  pages     = {2817--2825},
  year      = {2024},
  publisher = {Springer}
}


@article{brunete2021smart,
  title     = {Smart assistive architecture for the integration of IoT devices, robotic systems, and multimodal interfaces in healthcare environments},
  author    = {Brunete, Alberto and Gambao, Ernesto and Hernando, Miguel and Cedazo, Raquel},
  journal   = {Sensors},
  volume    = {21},
  number    = {6},
  pages     = {2212},
  url       = {https://www.mdpi.com/1424-8220/21/6/2212},
  year      = {2021},
  publisher = {MDPI}
}


@article{10.14778/3579075.3579081,
  author     = {Xie, Yuexiang and Wang, Zhen and Gao, Dawei and Chen, Daoyuan and Yao, Liuyi and Kuang, Weirui and Li, Yaliang and Ding, Bolin and Zhou, Jingren},
  title      = {FederatedScope: A Flexible Federated Learning Platform for Heterogeneity},
  year       = {2023},
  issue_date = {January 2023},
  publisher  = {VLDB Endowment},
  volume     = {16},
  number     = {5},
  issn       = {2150-8097},
  url        = {https://doi.org/10.14778/3579075.3579081},
  doi        = {10.14778/3579075.3579081},
  journal    = {Proc. VLDB Endow.},
  month      = {jan},
  pages      = {1059�1072},
  numpages   = {14}
}


@misc{peft,
  title        = {PEFT: State-of-the-art Parameter-Efficient Fine-Tuning methods},
  author       = {Sourab Mangrulkar and Sylvain Gugger and Lysandre Debut and Younes Belkada and Sayak Paul and Benjamin Bossan},
  howpublished = {\url{https://github.com/huggingface/peft}},
  year         = {2022}
}

@inproceedings{NEURIPS2023_c39578c8,
  author    = {Zhang, Zhiyuan and Chen, Deli and Zhou, Hao and Meng, Fandong and Zhou, Jie and Sun, Xu},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
  pages     = {62006--62031},
  publisher = {Curran Associates, Inc.},
  title     = {Fed-FA: Theoretically Modeling Client Data Divergence for Federated Language Backdoor Defense},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2023/file/c39578c86423df5f9e8834ce1cd456e4-Paper-Conference.pdf},
  volume    = {36},
  year      = {2023}
}


@inproceedings{peng2024fedpft,
  title     = {FedPFT: Federated Proxy Fine-Tuning of Foundation Models},
  author    = {Zhaopeng, Peng and Xiaoliang, Fan and Yufan, Chen and Zheng, Wang and Shirui, Pan and Chenglu, Wen and Ruisheng, Zhang and Cheng, Wang},
  booktitle = {Proceedings of the Thirty-Second International Joint Conference on
               Artificial Intelligence, {IJCAI-24}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  year      = {2024},
  month     = {aug},
  venue     = {IJCAI},
  github    = {https://github.com/pzp-dzd/FedPFT},
  tags      = {efficiency, knowledge distillation, selective tuning},
  url       = {https://doi.org/10.48550/arXiv.2404.11536}
}

@misc{fan2024fedmktfederatedmutualknowledge,
  title         = {FedMKT: Federated Mutual Knowledge Transfer for Large and Small Language Models},
  author        = {Tao Fan and Guoqiang Ma and Yan Kang and Hanlin Gu and Yuanfeng Song and Lixin Fan and Kai Chen and Qiang Yang},
  year          = {2024},
  eprint        = {2406.02224},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  tags          = {efficiency, knowledge distillation},
  url           = {https://arxiv.org/abs/2406.02224}
}

@misc{li2024federateddomainspecificknowledgetransfer,
  title         = {Federated Domain-Specific Knowledge Transfer on Large Language Models Using Synthetic Data},
  author        = {Haoran Li and Xinyuan Zhao and Dadi Guo and Hanlin Gu and Ziqian Zeng and Yuxing Han and Yangqiu Song and Lixin Fan and Qiang Yang},
  year          = {2024},
  eprint        = {2405.14212},
  archiveprefix = {arXiv},
  tags          = {efficiency, knowledge distillation},
  primaryclass  = {cs.CR},
  url           = {https://arxiv.org/abs/2405.14212}
}


@inproceedings{zhang2024federated,
  title     = {Federated Adaptation for Foundation Model-based Recommendations},
  author    = {Chunxu Zhang and Guodong Long and Hongkuan Guo and Xiao Fang and Yang Song and Zhaojie Liu and Guorui Zhou and Zijian Zhang and Yang Liu and Bo Yang},
  booktitle = {Proceedings of the Thirty-Second International Joint Conference on
               Artificial Intelligence, {IJCAI-24}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  year      = {2024},
  month     = {aug},
  venue     = {IJCAI},
  github    = {https://github.com/Zhangcx19/IJCAI-24-FedPA},
  tags      = {application, Recommendation Systems, efficiency, additive tuning, adapter tuning},
  url       = {https://doi.org/10.48550/arXiv.2404.11536}
}


@inproceedings{chen2023prompt,
  title     = {Prompt Federated Learning for Weather Forecasting: Toward Foundation Models on Meteorological Data},
  author    = {Chen, Shengchao and Long, Guodong and Shen, Tao and Jiang, Jing},
  booktitle = {Proceedings of the Thirty-Second International Joint Conference on
               Artificial Intelligence, {IJCAI-23}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Edith Elkind},
  pages     = {3532--3540},
  year      = {2023},
  month     = {8},
  venue     = {IJCAI},
  note      = {Main Track},
  tags      = {application, domain specific},
  doi       = {10.24963/ijcai.2023/393},
  url       = {https://doi.org/10.24963/ijcai.2023/393}
}

@inproceedings{chen2024federated,
  title     = {Federated Prompt Learning for Weather Foundation Models on Devices},
  author    = {Shengchao Chen and Guodong Long and Tao Shen and Jing Jiang and Chengqi Zhang},
  booktitle = {Proceedings of the Thirty-Second International Joint Conference on
               Artificial Intelligence, {IJCAI-24}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  year      = {2024},
  month     = {aug},
  venue     = {IJCAI},
  github    = {https://github.com/shengchaochen82/FedPoD},
  tags      = {application, domain specific},
  url       = {https://doi.org/10.48550/arXiv.2404.11536}
}


@inproceedings{zhangenhancing,
  title     = {Enhancing Storage and Computational Efficiency in Federated Multimodal Learning for Large-Scale Models},
  author    = {Zhang, Zixin and Qi, Fan and Xu, Changsheng},
  venue     = {ICML},
  month     = {jul},
  url       = {https://icml.cc/virtual/2024/poster/34071},
  year      = {2024},
  tags      = {efficiency, split learning, heterogeneous resource},
  github    = {https://github.com/M2FedSA/M-2FedSA},
  booktitle = {Forty-first International Conference on Machine Learning}
}


@article{chen2023feddat,
  title   = {FedDAT: An Approach for Foundation Model Finetuning in Multi-Modal Heterogeneous Federated Learning},
  volume  = {38},
  url     = {https://ojs.aaai.org/index.php/AAAI/article/view/29007},
  doi     = {10.1609/aaai.v38i10.29007},
  number  = {10},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  author  = {Chen, Haokun and Zhang, Yao and Krompass, Denis and Gu, Jindong and Tresp, Volker},
  year    = {2024},
  month   = {mar},
  venue   = {AAAI},
  github  = {https://github.com/HaokunChen245/FedDAT},
  tags    = {efficiency, knowledge distillation, additive tuning, adapter tuning},
  pages   = {11285-11293}
}

@article{ye2024emergingsafetyattackdefense,
  title         = {Emerging Safety Attack and Defense in Federated Instruction Tuning of Large Language Models},
  author        = {Rui Ye and Jingyi Chai and Xiangrui Liu and Yaodong Yang and Yanfeng Wang and Siheng Chen},
  year          = {2024},
  tags          = {trustworthiness, security, attack robustness, poisoning attack},
  eprint        = {2406.10630},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2406.10630}
}

@misc{li2024peftasanattackjailbreakinglanguagemodels,
  title         = {PEFT-as-an-Attack! Jailbreaking Language Models during Federated Parameter-Efficient Fine-Tuning},
  author        = {Shenghui Li and Edith C. -H. Ngai and Fanghua Ye and Thiemo Voigt},
  year          = {2024},
  month = {nov},
  eprint        = {2411.19335},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CR},
  tags          = {trustworthiness, security, attack robustness, poisoning attack},
  url           = {https://arxiv.org/abs/2411.19335}
}


@misc{lee2025exploringpotentialpromptinjection,
      title={Exploring Potential Prompt Injection Attacks in Federated Military LLMs and Their Mitigation},
      author={Youngjoon Lee and Taehyun Park and Yunho Lee and Jinu Gong and Joonhyuk Kang},
      year={2025},
      eprint={2501.18416},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      tags          = {trustworthiness, security, attack robustness, poisoning attack},
      url={https://arxiv.org/abs/2501.18416},
}

@ARTICLE{10818586,
  author={Wang, Fei and Li, Baochun},
  journal={IEEE Transactions on Big Data}, 
  title={Data Reconstruction and Protection in Federated Learning for Fine-Tuning Large Language Models}, 
  year={2024},
  volume={},
  month={dec},
  venue = {IEEE TBD},
  pages={1-13},
  keywords={Federated learning;Data models;Servers;Training;Transformers;Image reconstruction;Optimization;Training data;Large language models;Computational modeling;Federated learning;fine-tuning;gradient leakage attack;large language models},
  doi={10.1109/TBDATA.2024.3524105},
  tags = {trustworthiness, security, attack robustness, poisoning attack},
  url = {https://ieeexplore.ieee.org/abstract/document/10818586},
}



@article{beutel2020flower,
  title         = {Flower: A friendly federated learning research framework},
  author        = {Beutel, Daniel J and Topal, Taner and Mathur, Akhil and Qiu, Xinchi and Fernandez-Marques, Javier and Gao, Yan and Sani, Lorenzo and Li, Kwing Hei and Parcollet, Titouan and de Gusm{\~a}o, Pedro Porto Buarque and others},
  journal       = {arXiv preprint arXiv:2007.14390},
  github        = {https://github.com/adap/flower},
  url           = {https://flower.ai/},
  venue         = {Arxiv},
  developer     = {Flower},
  developerlogo = {data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0MDAgNDAxIj48c3R5bGU+LmEsLmJ7ZmlsbC1ydWxlOmV2ZW5vZGQ7Y2xpcC1ydWxlOmV2ZW5vZGR9LmF7ZmlsbDojMmMyZDM0fS5ie2ZpbGw6I2ZmZn0uY3tmaWxsOiMyMzFmMjB9PC9zdHlsZT48cGF0aCBjbGFzcz0iYSIgZD0ibTI5IDE5Mi0xNy0zMiAyOC02MiAzNi0zIDEzLTMwIDQ1LTIwIDMyIDEwIDE2LTIxaDYwbDE5IDIxIDI4LTcgNTEgMzIgMiAyOSAzMCA5IDE4IDYxLTE5IDI5IDEzIDMyLTIzIDU3LTM0IDQtNiAzMi01OCAyMi0yMi04LTIyIDIwaC02N2wtMTktMjItMjMgNy01NC0yOS0xLTM2LTM1LTE0LTktNTV6Ii8+PHBhdGggY2xhc3M9ImIiIGQ9Im02OSAxOTItMjEtMzQgMTUtMjkgMzctMyAxNC0zNiAyMi0xMCAzOSAxNCAyNC0yOGgyNmwyNCAyNSAzNC04IDI0IDE0IDQgMzggMzMgOSAxMCAzMC0yMSAzMSAxNSAzNy05IDI0LTQwIDctNiAzNS0zNCAxNC0zMC05LTIzIDIxaC0zOGwtMjQtMjctMzEgOS0yNS0xNnYtMzZsLTM3LTE1LTQtMjR6Ii8+PHBhdGggY2xhc3M9ImMiIGQ9Im0yNTIgMTM4IDI5IDI5LTEgNTEtMjkgMjgtODIgMS0yOS0yOC0xLTUyIDI5LTI5eiIvPjxwYXRoIGZpbGw9IiNmZmYiIGQ9Im0xODMgMjE0LTEwLTEwdi0yNGwxMC0xMGg1NWwxMCAxMHYyNGwtMTAgOXoiLz48L3N2Zz4=},
  tags          = {resources, frameworks},
  year          = {2020},
  month         = {jul}
}


@inproceedings{roth2022nvidia,
  title         = {{NVIDIA} {FLARE}: Federated Learning from Simulation to Real-World},
  author        = {Holger R Roth and Yan Cheng and Yuhong Wen and Isaac Yang and Ziyue Xu and YuanTing Hsieh and Kristopher Kersten and Ahmed Harouni and Can Zhao and Kevin Lu and Zhihong Zhang and Wenqi Li and Andriy Myronenko and Dong Yang and Sean Yang and Nicola Rieke and Abood Quraini and Chester Chen and Daguang Xu and Nic Ma and Prerna Dogra and Mona G Flores and Andrew Feng},
  booktitle     = {Workshop on Federated Learning: Recent Advances and New Challenges (in Conjunction with NeurIPS 2022)},
  year          = {2022},
  developer     = {Nvidia},
  developerlogo = {nvidia},
  month         = {jul},
  venue         = {FL\@NeurIPS},
  github        = {https://github.com/NVIDIA/NVFlare},
  tags          = {resources, frameworks},
  url           = {https://openreview.net/forum?id=hD9QaIQTL_f}
}


@article{he2020fedml,
  title         = {FedML: A Research Library and Benchmark for Federated Machine Learning},
  author        = {Chaoyang He and Songze Li and Jinhyun So and Xiao Zeng and Mi Zhang and Hongyi Wang and Xiaoyang Wang and Praneeth Vepakomma and Abhishek Singh and Hang Qiu and Xinghua Zhu and Jianzong Wang and Li Shen and Peilin Zhao and Yan Kang and Yang Liu and Ramesh Raskar and Qiang Yang and Murali Annavaram and Salman Avestimehr},
  year          = {2020},
  month         = {jul},
  eprint        = {2007.13518},
  archiveprefix = {arXiv},
  venue         = {SpicyFL},
  developer     = {FedML},
  developerlogo = {data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA1NTAgNTQ2Ij48c3R5bGU+LnMwe2ZpbGw6IzZlNjNhNH0uczF7ZmlsbDojZTA2NzVjfS5zMntmaWxsOiNlZGI5NTB9LnMze2ZpbGw6IzYxYjg1Mn08L3N0eWxlPjxwYXRoIGNsYXNzPSJzMCIgZD0iTTI3NiAyMTJzODYtODUgODYtMTI0YzAtMzQtMzktNjEtODYtNjFzLTg2IDI3LTg2IDYxYzAgMzkgODYgMTI0IDg2IDEyNCIvPjxwYXRoIGNsYXNzPSJzMSIgZD0iTTIxMiAyODZzLTg2LTg2LTEyNC04NmMtMzQgMC02MSAzOS02MSA4NnMyNyA4NiA2MSA4NmMzOSAwIDEyNC04NiAxMjQtODYiLz48cGF0aCBjbGFzcz0iczIiIGQ9Ik0yNzYgMzM0cy04NiA4Ni04NiAxMjRjMCAzNCAzOSA2MSA4NiA2MXM4Ni0yNyA4Ni02MWMwLTM5LTg2LTEyNC04Ni0xMjQiLz48cGF0aCBjbGFzcz0iczMiIGQ9Ik0zNDAgMjg2czg2IDg2IDEyNCA4NmMzNCAwIDYxLTM5IDYxLTg2cy0yNy04Ni02MS04NmMtMzkgMC0xMjQgODYtMTI0IDg2Ii8+PC9zdmc+},
  url           = {https://arxiv.org/abs/2007.13518},
  tags          = {resources, frameworks},
  github        = {https://github.com/FedML-AI/FedML},
  journal       = {arXiv preprint arXiv:2007.13518}
}
@misc{garcia2022flutescalableextensibleframework,
  title         = {FLUTE: A Scalable Extensible Framework for High-Performance Federated Learning Simulations},
  author        = {Mirian Hipolito Garcia and Andre Manoel and Daniel Madrigal Diaz and Fatemehsadat Mireshghallah and Robert Sim and Dimitrios Dimitriadis},
  year          = {2022},
  month         = {mar},
  eprint        = {2203.13789},
  tags          = {resources, frameworks},
  github        = {https://github.com/microsoft/msrflute},
  archiveprefix = {arXiv},
  developer     = {Microsoft},
  developerlogo = {data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMyAyMyI+PHBhdGggZmlsbD0iI2YzZjNmMyIgZD0iTTAgMGgyM3YyM0gweiIvPjxwYXRoIGZpbGw9IiNmMzUzMjUiIGQ9Ik0xIDFoMTB2MTBIMXoiLz48cGF0aCBmaWxsPSIjODFiYzA2IiBkPSJNMTIgMWgxMHYxMEgxMnoiLz48cGF0aCBmaWxsPSIjMDVhNmYwIiBkPSJNMSAxMmgxMHYxMEgxeiIvPjxwYXRoIGZpbGw9IiNmZmJhMDgiIGQ9Ik0xMiAxMmgxMHYxMEgxMnoiLz48L3N2Zz4=},
  venue         = {FL\@NeurIPS},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2203.13789}
}

@inproceedings{9826069,
  author        = {Ekmefjord, Morgan and Ait-Mlouk, Addi and Alawadi, Sadi and Åkesson, Mattias and Singh, Prashant and Spjuth, Ola and Toor, Salman and Hellander, Andreas},
  booktitle     = {2022 22nd IEEE International Symposium on Cluster, Cloud and Internet Computing (CCGrid)},
  title         = {Scalable federated machine learning with FEDn},
  year          = {2022},
  volume        = {},
  developer     = {Scaleout},
  month         = {may},
  developerlogo = {data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0MDAgMjM2Ij48c3R5bGU+LmF7ZmlsbDojMWIxYjFiO2ZpbGwtcnVsZTpldmVub2RkfTwvc3R5bGU+PHBhdGggY2xhc3M9ImEiIGQ9Ik0xMDMgODRjLTE0IDUtMjMgMTctMjUgMjktMyAyMiAxNiA0MiAzNCA0NSAxNiAyIDI4LTEwIDUyLTMzIDgxLTc3IDkxLTgzIDEwNC04NiAyOS02IDY5IDQgOTAgMzQgMjYgMzggNiA4MyA1IDg2LTIwIDMxLTUyIDQ4LTg0IDQ0LTI1LTMtNDEtMTctNDgtMjMtMyAzLTUgNi04IDEwIDMgMyA0MSAzNiA5MCAyNCA0Mi0xMSA2OC01MCA3MS04NiAxLTcgMy0zMS0xMi01Ni0yMS0zNS02NC01Mi05OS00Ni0yNiA0LTQ5IDI2LTk2IDcxLTM4IDM2LTUxIDUzLTY2IDQ5LTE0LTQtMjUtMjUtMTgtMzggNi0xMCAyNC0xNSA0Mi03IDItMiA0LTUgNi03LTEwLTEwLTI1LTE0LTM4LTEwbTMyIDgzYzQ2LTE3IDY0LTc4IDEzNC0xMTIgMjEtMTAgNTIgMSA3MCAyMCAxNSAxNiAxNyAzNiAxNyA0NCAxIDI1LTE1IDUyLTQyIDYzLTI0IDEwLTUyIDQtNzEtMTQgMy0zIDUtNiA3LTkgNSAzIDIyIDE2IDQ0IDEyIDMxLTUgNTUtNDAgNDgtNjctNi0yNC0zNy00NS02Mi0zOC00NiAxMy01NyA1OC0xMjYgMTA5LTE2IDEyLTI5IDE1LTQzIDE0LTMxLTMtNjQtMzktNjEtNzcgMC00IDMtMzAgMjYtNDYgMjQtMTcgNTktMTYgODcgNGwtMTAgMTFjLTI3LTIyLTY0LTE3LTgwIDQtMjEgMjctNCA3MSAyNCA4MyAxNSA3IDMxIDIgMzgtMW0xMzEtNzljNS0zIDE3LTkgMjktNiAxNiA0IDMzIDIwIDMxIDQxLTEgMTMtOSAyNS0yMiAzMS0xNCA2LTMxIDMtNDItOCAyLTIgNS01IDctOCAxIDEgMTMgMTEgMjcgNiAxMy01IDIxLTIwIDE2LTM3LTItNC02LTEwLTEzLTEyLTExLTQtMjMgMS0zMiA4LTQ1IDM0LTczIDkzLTEyOSAxMTAtNDEgMTMtMTAyLTIwLTExNi03M0M5IDk0IDQxIDM3IDkwIDI5YzUwLTkgODkgMTkgOTMgMjItMyA0LTcgNy0xMCAxMS0zOS0zMC05MC0yNy0xMTkgMi0yMCAyMC0yNyA1Mi0xOSA3OSAxMSAzNyA0OCA2MyA5MSA2MSA1NS04IDk1LTg3IDE0MC0xMTYiLz48L3N2Zz4=},
  number        = {},
  venue         = {CCGrid},
  pages         = {555-564},
  tags          = {resources, frameworks},
  url           = {https://ieeexplore.ieee.org/abstract/document/9826069},
  github        = {https://github.com/scaleoutsystems/fedn},
  keywords      = {Training;Analytical models;Computational modeling;Scalability;Machine learning;Production;Collaborative work;Federated machine learning;artificial intelligence;privacy},
  doi           = {10.1109/CCGrid54584.2022.00065}
}


@inproceedings{pmlr-v162-lai22a,
  title         = {{F}ed{S}cale: Benchmarking Model and System Performance of Federated Learning at Scale},
  author        = {Lai, Fan and Dai, Yinwei and Singapuram, Sanjay and Liu, Jiachen and Zhu, Xiangfeng and Madhyastha, Harsha and Chowdhury, Mosharaf},
  booktitle     = {Proceedings of the 39th International Conference on Machine Learning},
  pages         = {11814--11827},
  year          = {2022},
  editor        = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume        = {162},
  developer     = {SymbioticLab},
  developerlogo = {data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0MDAgNDAwIj48c3R5bGU+LmF7ZmlsbDojMjMxZjIwfS5ie2ZpbGw6I2YzNmMyMX0uYSwuYntmaWxsLXJ1bGU6ZXZlbm9kZH08L3N0eWxlPjxwYXRoIGNsYXNzPSJhIiBkPSJtMjIzIDE0NiA4NC0xMzUgMy00LTQ1IDEtNjAgMTA3TTIyOCAxNTZsMTggMzEgODUtMTQ3LTIyLTMwTTE1MiAyMDkgNjYgMzU2bDIyIDMyIDgzLTE0OE0xNzQgMjUyIDkyIDM4OWgyMTVsMjMtMzItMTgzIDYgNDUtODEiLz48cGF0aCBjbGFzcz0iYiIgZD0iTTI1NCA2IDg5IDcgNjYgNDBsMTczLTRNMjM0IDQ0IDY2IDQwbDE1NiAyNzRoMzhMMTI4IDc1bDg5LTIiLz48cGF0aCBjbGFzcz0iYiIgZD0ibTEzOCA4MyAxMzYgMjM3LTkxIDEtMTggMzAgMTY4IDNMMTc3IDg0Ii8+PC9zdmc+},
  series        = {Proceedings of Machine Learning Research},
  month         = {jul},
  venue         = {ICML},
  publisher     = {PMLR},
  tags          = {resources, frameworks},
  github        = {https://github.com/SymbioticLab/FedScale},
  pdf           = {https://proceedings.mlr.press/v162/lai22a/lai22a.pdf},
  url           = {https://proceedings.mlr.press/v162/lai22a.html}
}

@article{JMLR:v24:22-0440,
  author        = {Dun Zeng and Siqi Liang and Xiangjing Hu and Hui Wang and Zenglin Xu},
  title         = {FedLab: A Flexible Federated Learning Framework},
  journal       = {Journal of Machine Learning Research},
  year          = {2023},
  month         = {jan},
  volume        = {24},
  venue         = {JMLR},
  developer     = {SMILELab},
  developerlogo = {data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0MTAgNDEwIiBzdHlsZT0iZW5hYmxlLWJhY2tncm91bmQ6bmV3IDAgMCA0MTAgNDEwIiB4bWw6c3BhY2U9InByZXNlcnZlIj48c3R5bGU+LnN0MHtmaWxsOiNmZjUyMDd9LnN0MSwuc3Qye2ZpbGw6I2UwMTkxNDtmaWxsLXJ1bGU6ZXZlbm9kZDtjbGlwLXJ1bGU6ZXZlbm9kZH0uc3Qye2ZpbGw6IzEzODljNH08L3N0eWxlPjxyZWN0IHg9IjE2OSIgeT0iMTYxIiBjbGFzcz0ic3QwIiB3aWR0aD0iNTMiIGhlaWdodD0iNTEiLz48cGF0aCBjbGFzcz0ic3QxIiBkPSJNMzkxIDkwYy01IDIwLTQxIDE1My0xNTggMTk3LTE5IDctNzkgMzAtMTI5IDMtNzMtNDAtNzItMTU0LTgwLTE1M3MtOCAxMDcgNTggMTcyYzM1IDM0IDk2IDYxIDE0OCA0MyA4MS0yNyAxMTEtMTQ4IDE1My0xMzggMTIgMyAxNyAxNCAyMyAxMi01LTQ1LTEwLTkxLTE1LTEzNiIvPjxyZWN0IHg9IjgxIiB5PSI5NiIgY2xhc3M9InN0MiIgd2lkdGg9IjU0IiBoZWlnaHQ9IjU0Ii8+PHJlY3QgeD0iMjIyIiB5PSI4NyIgY2xhc3M9InN0MiIgd2lkdGg9Ijc0IiBoZWlnaHQ9Ijc0Ii8+PC9zdmc+},
  github        = {https://github.com/SMILELab-FL/FedLab},
  number        = {100},
  tags          = {resources, frameworks},
  pages         = {1--7},
  url           = {http://jmlr.org/papers/v24/22-0440.html}
}

@article{federatedscope,
  title         = {FederatedScope: A Flexible Federated Learning Platform for Heterogeneity},
  author        = {Xie, Yuexiang and Wang, Zhen and Gao, Dawei and Chen, Daoyuan and Yao, Liuyi and Kuang, Weirui and Li, Yaliang and Ding, Bolin and Zhou, Jingren},
  journal       = {Proceedings of the VLDB Endowment},
  venue         = {VLDB},
  github        = {https://github.com/alibaba/FederatedScope},
  volume        = {16},
  month         = {sep},
  developer     = {Alibaba},
  developerlogo = {alibabadotcom},
  tags          = {resources, frameworks},
  url           = {https://www.vldb.org/pvldb/vol16/p1059-li.pdf},
  number        = {5},
  pages         = {1059--1072},
  year          = {2023}
}


@article{JMLR:v22:20-815,
  author        = {Yang Liu and Tao Fan and Tianjian Chen and Qian Xu and Qiang Yang},
  title         = {FATE: An Industrial Grade Platform for Collaborative Learning With Data Protection},
  journal       = {Journal of Machine Learning Research},
  year          = {2021},
  month         = {aug},
  volume        = {22},
  number        = {226},
  pages         = {1--6},
  tags          = {resources, frameworks},
  github        = {https://github.com/FederatedAI/FATE},
  venue         = {JMLR},
  developer     = {Webank},
  developerlogo = {data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0MDAgNDgyIj48c3R5bGU+LmEsLmJ7ZmlsbC1ydWxlOmV2ZW5vZGR9LmF7ZmlsbDojMzYzNTM1fS5ie2ZpbGw6I2QwMzExZX08L3N0eWxlPjxwYXRoIGNsYXNzPSJhIiBkPSJNMjIzIDdjLTg3IDMtMTM2IDk0LTEzOSA5OS0yMyAwLTQxIDYtNDMgMTUtMyAxMCAxNiAyNyA0OCAzNy0yNSA0MC00OSA1Ny02MCA4M0M2IDI5MyAwIDMzNyA4IDM2M2M5IDMyIDM5IDQ2IDMyIDY1LTYgMTctMzIgMTYtMzMgMjMgMCAxNyAxNjQgMjEgMjYwIDIzIDM0IDEgNzkgMSA5MC0yMSAxMS0yMyAzLTQ4LTMtODEtMTktMTA3IDUxLTE0MyAzNS0yMjRDMzc1IDgxIDMwNiA0IDIyMyA3bS01NyAyNTZjLTMyIDg1IDE5IDE2NC01IDE3OC0yMCAxMi04Mi0zMy0xMDMtOTUtMzEtOTQgNTMtMTgxIDU2LTE4NSAyMi03MiA3Ny0xMDQgMTA2LTkzIDI0IDkgMzkgNTIgMzMgMTAwLTI4IDE2LTY5IDQ2LTg3IDk1Ii8+PHBhdGggY2xhc3M9ImEiIGQ9Ik0xODYgMTA2Yy04LTUtMTgtNC0yNSAxLTkgOC05IDIzLTEgMzEgOSA5IDI2IDYgMzItNSA1LTkgMi0yMS03LTI3Ii8+PHBhdGggY2xhc3M9ImIiIGQ9Ik0zOTAgMTQ4Yy0yNCA2LTQ5IDExLTc3IDE1LTkxIDEyLTE3MSA0LTIzMS05LTExIDIyLTI5IDQxLTQwIDYzIDY2IDE4IDEyOSAyOSAxNjkgMzMgODggOCAxNTAgMTMgMTc1LTIzIDE3LTIzIDExLTU2IDQtNzkiLz48L3N2Zz4=},
  url           = {http://jmlr.org/papers/v22/20-815.html}
}


@article{openfl_citation,
  author        = {Foley, Patrick and Sheller, Micah J and Edwards, Brandon and Pati, Sarthak and Riviera, Walter and Sharma, Mansi and Moorthy, Prakash Narayana and Wang, Shi-han and Martin, Jason and Mirhaji, Parsa and Shah, Prashant and Bakas, Spyridon},
  title         = {OpenFL: the open federated learning library},
  journal       = {Physics in Medicine \& Biology},
  url           = {http://iopscience.iop.org/article/10.1088/1361-6560/ac97d9},
  github        = {https://github.com/securefederatedai/openfl},
  developer     = {Intel},
  developerlogo = {Intel},
  tags          = {resources, frameworks},
  year          = {2022},
  month         = {oct},
  doi           = {10.1088/1361-6560/ac97d9},
  venue         = {PMB},
  publisher     = {IOP Publishing}
}


@article{ziller2021pysyft,
  title         = {Pysyft: A library for easy federated learning},
  author        = {Ziller, Alexander and Trask, Andrew and Lopardo, Antonio and Szymkow, Benjamin and Wagner, Bobby and Bluemke, Emma and Nounahon, Jean-Mickael and Passerat-Palmbach, Jonathan and Prakash, Kritika and Rose, Nick and others},
  journal       = {Federated Learning Systems: Towards Next-Generation AI},
  venue         = {FLS},
  url           = {https://link.springer.com/chapter/10.1007/978-3-030-70604-3_5},
  developer     = {OpenMined},
  github        = {https://github.com/OpenMined/PySyft},
  tags          = {resources, frameworks},
  developerlogo = {OpenMined},
  pages         = {111--139},
  year          = {2021},
  month         = {jun},
  publisher     = {Springer}
}

@inproceedings{10.1145/3580305.3599825,
  author    = {Wu, Feijie and Li, Zitao and Li, Yaliang and Ding, Bolin and Gao, Jing},
  title     = {FedBiOT: LLM Local Fine-tuning in Federated Learning without Full Model},
  year      = {2024},
  publisher = {Association for Computing Machinery},
  url       = {https://arxiv.org/abs/2406.17706},
  github    = {https://github.com/HarliWu/FedBiOT},
  doi       = {10.1145/3580305.3599825},
  booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  numpages  = {11},
  venue     = {KDD},
  month     = {aug},
  tags      = {efficiency, LoRA, reparameterization-based}
}

@article{zhang2024fed,
  title   = {Fed-piLot: Optimizing LoRA Assignment for Efficient Federated Foundation Model Fine-Tuning},
  author  = {Zhang, Zikai and Xu, Jiahao and Liu, Ping and Hu, Rui},
  journal = {arXiv preprint arXiv:2410.10200},
  url     = {https://arxiv.org/abs/2410.10200},
  tags    = {efficiency, reparameterization-based, LoRA, heterogeneous resource},
  year    = {2024}
}

@misc{zhang2024personalizedfederatedfinetuningllms,
      title={Personalized Federated Fine-Tuning for LLMs via Data-Driven Heterogeneous Model Architectures},
      author={Yicheng Zhang and Zhen Qin and Zhaomin Wu and Shuiguang Deng},
      year={2024},
      eprint={2411.19128},
      archivePrefix={arXiv},
      tags    = {efficiency, reparameterization-based, LoRA, heterogeneous resource},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2411.19128},
}


@inproceedings{
anonymous2025closedform,
title={Closed-Form Merging of Parameter-Efficient Modules for Federated Continual Learning},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
venue = {ICLR},
month = {apr},
author={Riccardo Salami and Pietro Buzzega and Matteo Mosconi and Jacopo Bonato and Luigi Sabetta and Simone Calderara},
tags    = {efficiency, reparameterization-based, LoRA},
url={https://openreview.net/forum?id=ROpY0qRUXL}
}
