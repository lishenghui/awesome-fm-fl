

ğŸ˜Awesome Foundation Models and Federated LearningğŸ§ â•ğŸŒ 
=============================================================

.. raw:: html

   <div align="center">
   <a href="https://arxiv.org/pdf/2406.12844.pdf">
       <img alt="Tests Status" src="https://img.shields.io/badge/arXiv-2406.12844-red?logo=arxiv&style=flat-square&link=https%3A%2F%2Farxiv.org%2Fpdf%2F2206.05359.pdf"/>
   </a>
   <a href="https://arxiv.org/pdf/2406.12844.pdf">
       <img alt="awesome" src="https://awesome.re/badge-flat.svg"/>
   </a>
   <a href="https://github.com/lishenghui/awesome-fm-fl">
       <img alt="Build Status" src="https://img.shields.io/github/last-commit/lishenghui/awesome-fm-fl"/>
   </a>
   <a href="https://github.com/lishenghui/blades/awesome-fm-fl/master/LICENSE">
       <img alt="License" src="https://img.shields.io/github/license/lishenghui/awesome-fm-fl"/>
   </a>
   </div>


This repository is primarily based on our survey paper ğŸ“šğŸ”:


.. raw:: html

   <div align="center">
        <strong><a href="https://arxiv.org/abs/2406.12844"> Synergizing Foundation Models and Federated Learning: A Survey </a></strong>
        <div>
            <a href="https://lishenghui.github.io/">Shenghui Li,</a>
            <a href="https://www.fanghuaye.xyz/">Fanghua Ye,</a>
            <a href="https://mengf1.github.io/">Meng Fang,</a>
            <a href="https://scholar.google.com/citations?user=ozQfDTkAAAAJ&hl=en">Jiaxu Zhao,</a>
           <a href="https://scholar.google.com/citations?hl=en&user=9dJZ9RQAAAAJ">Yun-Hin Chan,</a>
           <a href="https://www.eee.hku.hk/people/echngai/">Edith C.-H. Ngai,</a>
           <a href="https://scholar.google.se/citations?user=xSXvpjEAAAAJ">Thiemo Voigt</a>
        </div>
        <div align="left">
            Unlike smaller models, Foundation Models (FMs) ğŸ§ , such as LLMs and VLMs, are built upon vast amounts of training data ğŸ“Š. While general FMs can use public data, domain-specific FMs require proprietary data for pre-training and fine-tuning, raising privacy concerns ğŸ”’. Federated Learning (FL) ğŸ¤ğŸ’», a compelling privacy-preserving approach, enables collaborative learning across distributed datasets while maintaining data privacyğŸ›¡ï¸. Synergizing FM and FL ğŸ§ â•ğŸŒ offers a promising way to address data availability and privacy challenges in FM development, potentially revolutionizing large-scale machine learning in sensitive domains. 
        </div>
        <div style="margin-bottom: 10px;"></div>
    </div>



---

.. raw:: html

   <p align=center>
        <img src="https://github.com/lishenghui/awesome-fm-fl/blob/main/docs/images/fmfltaxonomy.png" width="1000" alt="Taxonomy">
   </p>

---

|
ğŸ™If you find this survey useful for your research, please consider citing:

::

    @misc{li2024synergizing,
          title={Synergizing Foundation Models and Federated Learning: A Survey},
          author={Shenghui Li and Fanghua Ye and Meng Fang and Jiaxu Zhao and Yun-Hin Chan and Edith C. -H. Ngai and Thiemo Voigt},
          year={2024},
          eprint={2406.12844},
          archivePrefix={arXiv}
    }

.. contents:: Table of Contents
    :depth: 3
    :local:
    :class: collapsible

